{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpfilomeno/JupiterNotebooks/blob/main/Whisper_STT_and_Coqui_TTS_VIDEO%3Dmodified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_HkOd4jwqIb"
      },
      "source": [
        "**Fine tune a VITS model with the Coqui TTS framework using audio samples of your choice.**\n",
        "\n",
        "Thank you to all of the [Coqui TTS](https://https://github.com/coqui-ai/TTS) contributors, the OpenAI team,and [@Thorsten-Voice](https://https://www.youtube.com/c/ThorstenMueller ) (I think he wrote this original script). I have no idea who wrote the rnnoise loop, but they are great, too. I just smash things together. [-nn](https://https://www.youtube.com/c/NanoNomad )\n",
        "\n",
        "If you have run the script before, and want to examine your training session using Tensorboard, set your dataset directories, then skip to the bottom section to load Tensorboard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOoSyCc8h4WI"
      },
      "source": [
        "Run this cell to connect your Google Drive account to save files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RUb7_iJu1mb",
        "outputId": "fb4013be-7d1d-4023-8a2a-762706303a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UO0B3tVbPAKc"
      },
      "source": [
        "Set dataset and trainer output directory (model states saved here, subdirectory of dataset). Set upload_dir and place all audio files (Wav, mp3) in upload directory which will be /content/drive/MyDrive/{upload_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GqNvXLc9ltKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee4d812-f8bb-4d05-ff6b-3d9565dc2b53",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/mp3uploads’: File exists\n"
          ]
        }
      ],
      "source": [
        "dataset_name = \"me2-dataset\" #@param {type:\"string\"}\n",
        "output_directory = \"traineroutput\" #@param {type:\"string\"}\n",
        "upload_dir = \"mp3uploads\" #@param {type:\"string\"}\n",
        "upload_dir = \"/content/drive/MyDrive/\" + upload_dir\n",
        "!mkdir $upload_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleanup previous audio processing"
      ],
      "metadata": {
        "id": "k2iOHpvbaL9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive/MyDrive/$upload_dir/out\n",
        "!rm -rf /content/drive/MyDrive/$dataset_name/converted"
      ],
      "metadata": {
        "id": "R-PoyqhKaLFP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIvwEf9zydzN"
      },
      "source": [
        "Download and Build Rnnoise (https://github.com/xiph/rnnoise) and Requirements (Optional if not processing .wav files for a new dataset. Multiple passes of rnnoise over samples may degrade audio quality. You should also preview your output dataset before training to ensure that the processing has not degraded any of your samples.  Occasionally, it will denoise too much of the tail end of phrases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HigwgxZxEXf",
        "outputId": "9f2df9c6-8647-49db-ba8e-1a95b60b9085",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyloudnorm in /usr/local/lib/python3.8/dist-packages (0.1.1)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.8/dist-packages (from pyloudnorm) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.8/dist-packages (from pyloudnorm) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from pyloudnorm) (1.10.1)\n",
            "fatal: destination path 'rnnoise' already exists and is not an empty directory.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'python-dev-is-python2' instead of 'python-dev'\n",
            "autoconf is already the newest version (2.69-11.1).\n",
            "automake is already the newest version (1:1.16.1-4ubuntu6).\n",
            "libtool is already the newest version (2.4.6-14).\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu4).\n",
            "python-dev-is-python2 is already the newest version (2.7.17-4).\n",
            "curl is already the newest version (7.68.0-1ubuntu2.16).\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "sox is already the newest version (14.4.2+git20190427-2+deb11u1build0.20.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "/content/rnnoise\n",
            "Updating build configuration files for rnnoise, please wait....\n",
            "libtoolize: putting auxiliary files in '.'.\n",
            "libtoolize: linking file './ltmain.sh'\n",
            "libtoolize: putting macros in AC_CONFIG_MACRO_DIRS, 'm4'.\n",
            "libtoolize: linking file 'm4/libtool.m4'\n",
            "libtoolize: linking file 'm4/ltoptions.m4'\n",
            "libtoolize: linking file 'm4/ltsugar.m4'\n",
            "libtoolize: linking file 'm4/ltversion.m4'\n",
            "libtoolize: linking file 'm4/lt~obsolete.m4'\n",
            "configure.ac:19: installing './compile'\n",
            "configure.ac:22: installing './missing'\n",
            "Makefile.am: installing './depcomp'\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking whether gcc understands -c and -o together... yes\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /usr/bin/grep\n",
            "checking for egrep... /usr/bin/grep -E\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking minix/config.h usability... no\n",
            "checking minix/config.h presence... no\n",
            "checking for minix/config.h... no\n",
            "checking whether it is safe to define __EXTENSIONS__... yes\n",
            "checking for special C compiler options needed for large files... no\n",
            "checking for _FILE_OFFSET_BITS value needed for large files... no\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /usr/bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports the include directive... yes (GNU style)\n",
            "checking whether make supports nested variables... yes\n",
            "checking dependency style of gcc... gcc3\n",
            "checking whether to enable maintainer-specific portions of Makefiles... yes\n",
            "checking for inline... inline\n",
            "checking build system type... x86_64-pc-linux-gnu\n",
            "checking host system type... x86_64-pc-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /usr/bin/sed\n",
            "checking for fgrep... /usr/bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking how to convert x86_64-pc-linux-gnu file names to x86_64-pc-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-pc-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... no\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "checking for a working dd... /usr/bin/dd\n",
            "checking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking whether make supports nested variables... (cached) yes\n",
            "checking if gcc supports -pedantic flag... yes\n",
            "checking if gcc supports -Wall flag... yes\n",
            "checking if gcc supports -Wextra flag... yes\n",
            "checking if gcc supports -Wno-sign-compare flag... yes\n",
            "checking if gcc supports -Wno-parentheses flag... yes\n",
            "checking if gcc supports -Wno-long-long flag... yes\n",
            "checking for cos in -lm... yes\n",
            "checking for gcc way to treat warnings as errors... -Werror\n",
            "checking if gcc supports __attribute__(( visibility(\"default\") ))... yes\n",
            "checking if gcc supports -fvisibility=hidden... yes\n",
            "checking for doxygen... no\n",
            "checking for dot... yes\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating rnnoise.pc\n",
            "config.status: creating rnnoise-uninstalled.pc\n",
            "config.status: creating doc/Doxyfile\n",
            "config.status: creating config.h\n",
            "config.status: config.h is unchanged\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "configure:\n",
            "------------------------------------------------------------------------\n",
            "  rnnoise unknown: Automatic configuration OK.\n",
            "\n",
            "    Assertions ................... no\n",
            "\n",
            "    Hidden visibility ............ yes\n",
            "\n",
            "    API code examples ............ yes\n",
            "    API documentation ............ yes\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "test -z \"librnnoise.la\" || rm -f librnnoise.la\n",
            "rm -f ./so_locations\n",
            "rm -rf .libs _libs\n",
            "rm -rf examples/.libs examples/_libs\n",
            "rm -rf src/.libs src/_libs\n",
            " rm -f examples/rnnoise_demo\n",
            "rm -f *.o\n",
            "rm -f examples/*.o\n",
            "rm -f src/*.o\n",
            "rm -f src/*.lo\n",
            "rm -f *.lo\n",
            "make  all-am\n",
            "make[1]: Entering directory '/content/rnnoise'\n",
            "  CC       examples/rnnoise_demo.o\n",
            "\u001b[01m\u001b[Kexamples/rnnoise_demo.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmain\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Kexamples/rnnoise_demo.c:48:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’, declared with attribute warn_unused_result [\u001b[01;35m\u001b[K-Wunused-result\u001b[m\u001b[K]\n",
            "   48 |     \u001b[01;35m\u001b[Kfread(tmp, sizeof(short), FRAME_SIZE, f1)\u001b[m\u001b[K;\n",
            "      |     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "  CC       src/denoise.lo\n",
            "  CC       src/rnn.lo\n",
            "  CC       src/rnn_data.lo\n",
            "  CC       src/rnn_reader.lo\n",
            "  CC       src/pitch.lo\n",
            "  CC       src/kiss_fft.lo\n",
            "  CC       src/celt_lpc.lo\n",
            "  CCLD     librnnoise.la\n",
            "  CCLD     examples/rnnoise_demo\n",
            "make[1]: Leaving directory '/content/rnnoise'\n"
          ]
        }
      ],
      "source": [
        "!pip install pyloudnorm\n",
        "!git clone https://github.com/xiph/rnnoise.git\n",
        "!sudo apt-get install curl autoconf automake libtool python-dev pkg-config sox ffmpeg\n",
        "%cd /content/rnnoise\n",
        "!sh autogen.sh\n",
        "!sh configure\n",
        "!make clean\n",
        "!make"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achSZMoMNcCQ"
      },
      "source": [
        "Install Sox, Install OpenAI Whisper STT+Translation (https://github.com/openai/whisper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wDN_GAyvNbeG",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c182851a-2c24-48e7-9a59-faa430d1f39d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "sox is already the newest version (14.4.2+git20190427-2+deb11u1build0.20.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "fatal: destination path 'whisper' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-1lgz3tjg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-1lgz3tjg\n",
            "  Resolved https://github.com/openai/whisper.git to commit 3e1780fd37686666f568be9c99f5b5e3e4f2eb92\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.1.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.26.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.13.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!sudo apt install sox\n",
        "!git clone https://github.com/openai/whisper.git\n",
        "!pip install git+https://github.com/openai/whisper.git \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWzQveIIy7QW"
      },
      "source": [
        "Install Coqui TTS (https://github.com/coqui-ai/TTS), espeak-ng phonemeizer (https://github.com/espeak-ng/espeak-ng), download Coqui TTS source and examples from GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jyCWXW_2y_nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "118a82bc-2034-43e1-b2c4-e29ce7963b17",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "espeak-ng is already the newest version (1.50+dfsg-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "fatal: destination path 'TTS' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: TTS in /usr/local/lib/python3.8/dist-packages (0.11.1)\n",
            "Requirement already satisfied: fsspec>=2021.04.0 in /usr/local/lib/python3.8/dist-packages (from TTS) (2023.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from TTS) (3.5.3)\n",
            "Requirement already satisfied: numpy==1.21.6 in /usr/local/lib/python3.8/dist-packages (from TTS) (1.21.6)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (from TTS) (0.13.1+cu116)\n",
            "Requirement already satisfied: mecab-python3==1.0.5 in /usr/local/lib/python3.8/dist-packages (from TTS) (1.0.5)\n",
            "Requirement already satisfied: gruut[de]==2.2.3 in /usr/local/lib/python3.8/dist-packages (from TTS) (2.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from TTS) (4.64.1)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.8/dist-packages (from TTS) (0.0.17)\n",
            "Requirement already satisfied: numba==0.55.1 in /usr/local/lib/python3.8/dist-packages (from TTS) (0.55.1)\n",
            "Requirement already satisfied: unidic-lite==1.0.8 in /usr/local/lib/python3.8/dist-packages (from TTS) (1.0.8)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.8/dist-packages (from TTS) (0.4.1)\n",
            "Requirement already satisfied: cython==0.29.28 in /usr/local/lib/python3.8/dist-packages (from TTS) (0.29.28)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (from TTS) (2.2.3)\n",
            "Requirement already satisfied: pysbd in /usr/local/lib/python3.8/dist-packages (from TTS) (0.3.4)\n",
            "Requirement already satisfied: trainer==0.0.20 in /usr/local/lib/python3.8/dist-packages (from TTS) (0.0.20)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.8/dist-packages (from TTS) (0.48.0)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from TTS) (1.10.1)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from TTS) (1.13.1+cu116)\n",
            "Requirement already satisfied: librosa==0.8.0 in /usr/local/lib/python3.8/dist-packages (from TTS) (0.8.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.8/dist-packages (from TTS) (0.12.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from TTS) (1.3.5)\n",
            "Requirement already satisfied: umap-learn==0.5.1 in /usr/local/lib/python3.8/dist-packages (from TTS) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from TTS) (23.0)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from TTS) (0.1.2)\n",
            "Requirement already satisfied: inflect==5.6.0 in /usr/local/lib/python3.8/dist-packages (from TTS) (5.6.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from TTS) (3.7)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.8/dist-packages (from TTS) (0.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from TTS) (6.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.8/dist-packages (from TTS) (0.42.1)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (1.2.0)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (1.1.7)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (2.12.1)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (2.8.8)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (0.9.9)\n",
            "Requirement already satisfied: num2words<1.0.0,>=0.5.10 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (0.5.12)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (5.12.0)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.8/dist-packages (from gruut[de]==2.2.3->TTS) (2.0.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (0.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (1.2.1)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (3.0.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (1.7.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.8.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /usr/local/lib/python3.8/dist-packages (from numba==0.55.1->TTS) (0.38.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.55.1->TTS) (57.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from trainer==0.0.20->TTS) (5.4.8)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from trainer==0.0.20->TTS) (3.19.6)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (from trainer==0.0.20->TTS) (2.6)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.8/dist-packages (from umap-learn==0.5.1->TTS) (0.5.8)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile->TTS) (1.15.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7->TTS) (4.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (6.0.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (2.1.2)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (3.1.2)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from flask->TTS) (8.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->TTS) (8.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->TTS) (2022.6.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->TTS) (2022.7.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.8/dist-packages (from dateparser~=1.1.0->gruut[de]==2.2.3->TTS) (1.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->flask->TTS) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->flask->TTS) (2.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from jsonlines~=1.2.0->gruut[de]==2.2.3->TTS) (1.15.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from num2words<1.0.0,>=0.5.10->gruut[de]==2.2.3->TTS) (0.6.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS) (2.25.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa==0.8.0->TTS) (3.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.8.0->TTS) (3.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa==0.8.0->TTS) (4.0.0)\n",
            " Name format: type/language/dataset/model\n",
            " 1: tts_models/multilingual/multi-dataset/your_tts\n",
            " 2: tts_models/bg/cv/vits\n",
            " 3: tts_models/cs/cv/vits\n",
            " 4: tts_models/da/cv/vits\n",
            " 5: tts_models/et/cv/vits\n",
            " 6: tts_models/ga/cv/vits\n",
            " 7: tts_models/en/ek1/tacotron2\n",
            " 8: tts_models/en/ljspeech/tacotron2-DDC\n",
            " 9: tts_models/en/ljspeech/tacotron2-DDC_ph\n",
            " 10: tts_models/en/ljspeech/glow-tts\n",
            " 11: tts_models/en/ljspeech/speedy-speech\n",
            " 12: tts_models/en/ljspeech/tacotron2-DCA\n",
            " 13: tts_models/en/ljspeech/vits [already downloaded]\n",
            " 14: tts_models/en/ljspeech/vits--neon\n",
            " 15: tts_models/en/ljspeech/fast_pitch\n",
            " 16: tts_models/en/ljspeech/overflow\n",
            " 17: tts_models/en/ljspeech/neural_hmm\n",
            " 18: tts_models/en/vctk/vits\n",
            " 19: tts_models/en/vctk/fast_pitch\n",
            " 20: tts_models/en/sam/tacotron-DDC\n",
            " 21: tts_models/en/blizzard2013/capacitron-t2-c50\n",
            " 22: tts_models/en/blizzard2013/capacitron-t2-c150_v2\n",
            " 23: tts_models/es/mai/tacotron2-DDC\n",
            " 24: tts_models/es/css10/vits\n",
            " 25: tts_models/fr/mai/tacotron2-DDC\n",
            " 26: tts_models/fr/css10/vits\n",
            " 27: tts_models/uk/mai/glow-tts\n",
            " 28: tts_models/uk/mai/vits\n",
            " 29: tts_models/zh-CN/baker/tacotron2-DDC-GST\n",
            " 30: tts_models/nl/mai/tacotron2-DDC\n",
            " 31: tts_models/nl/css10/vits\n",
            " 32: tts_models/de/thorsten/tacotron2-DCA\n",
            " 33: tts_models/de/thorsten/vits\n",
            " 34: tts_models/de/thorsten/tacotron2-DDC\n",
            " 35: tts_models/de/css10/vits-neon\n",
            " 36: tts_models/ja/kokoro/tacotron2-DDC\n",
            " 37: tts_models/tr/common-voice/glow-tts\n",
            " 38: tts_models/it/mai_female/glow-tts\n",
            " 39: tts_models/it/mai_female/vits\n",
            " 40: tts_models/it/mai_male/glow-tts\n",
            " 41: tts_models/it/mai_male/vits\n",
            " 42: tts_models/ewe/openbible/vits\n",
            " 43: tts_models/hau/openbible/vits\n",
            " 44: tts_models/lin/openbible/vits\n",
            " 45: tts_models/tw_akuapem/openbible/vits\n",
            " 46: tts_models/tw_asante/openbible/vits\n",
            " 47: tts_models/yor/openbible/vits\n",
            " 48: tts_models/hu/css10/vits\n",
            " 49: tts_models/el/cv/vits\n",
            " 50: tts_models/fi/css10/vits\n",
            " 51: tts_models/hr/cv/vits\n",
            " 52: tts_models/lt/cv/vits\n",
            " 53: tts_models/lv/cv/vits\n",
            " 54: tts_models/mt/cv/vits\n",
            " 55: tts_models/pl/mai_female/vits\n",
            " 56: tts_models/pt/cv/vits\n",
            " 57: tts_models/ro/cv/vits\n",
            " 58: tts_models/sk/cv/vits\n",
            " 59: tts_models/sl/cv/vits\n",
            " 60: tts_models/sv/cv/vits\n",
            " 61: tts_models/ca/custom/vits\n",
            " 62: tts_models/fa/custom/glow-tts\n",
            " Name format: type/language/dataset/model\n",
            " 1: vocoder_models/universal/libri-tts/wavegrad\n",
            " 2: vocoder_models/universal/libri-tts/fullband-melgan\n",
            " 3: vocoder_models/en/ek1/wavegrad\n",
            " 4: vocoder_models/en/ljspeech/multiband-melgan\n",
            " 5: vocoder_models/en/ljspeech/hifigan_v2\n",
            " 6: vocoder_models/en/ljspeech/univnet\n",
            " 7: vocoder_models/en/blizzard2013/hifigan_v2\n",
            " 8: vocoder_models/en/vctk/hifigan_v2\n",
            " 9: vocoder_models/en/sam/hifigan_v2\n",
            " 10: vocoder_models/nl/mai/parallel-wavegan\n",
            " 11: vocoder_models/de/thorsten/wavegrad\n",
            " 12: vocoder_models/de/thorsten/fullband-melgan\n",
            " 13: vocoder_models/de/thorsten/hifigan_v1\n",
            " 14: vocoder_models/ja/kokoro/hifigan_v1\n",
            " 15: vocoder_models/uk/mai/multiband-melgan\n",
            " 16: vocoder_models/tr/common-voice/hifigan\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%cd /content\n",
        "!sudo apt-get install espeak-ng\n",
        "!git clone https://github.com/coqui-ai/TTS.git\n",
        "!pip install TTS\n",
        "!tts --list_models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuK3Veok3zin"
      },
      "source": [
        "Convert mp3 files in upload_dir to wav as 22050hz mono wav\n",
        "Place output wav files in directory named 'out'.\n",
        "Copy any uploaded .wav files to 'out' as 22050hz mono wav.\n",
        "\n",
        "Make directory 'splits'. Use sox to split wav files into 8 second segments, placed in 'splits'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b58_cakYtYKB",
        "outputId": "340ae5f5-fbac-403f-d625-41a2c4f3c711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/mp3uploads\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a2.mp3':\n",
            "  Duration: 00:00:59.77, start: 0.025057, bitrate: 133 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 133 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a2.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=    2572kB time=00:00:59.73 bitrate= 352.8kbits/s speed= 127x    \n",
            "video:0kB audio:2572kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.002961%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a3.mp3':\n",
            "  Duration: 00:01:02.20, start: 0.025057, bitrate: 131 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 131 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a3.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=    2677kB time=00:01:02.15 bitrate= 352.8kbits/s speed= 112x    \n",
            "video:0kB audio:2677kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.002846%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a5.mp3':\n",
            "  Duration: 00:01:01.00, start: 0.025057, bitrate: 132 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 132 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a5.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=    2626kB time=00:01:00.96 bitrate= 352.8kbits/s speed= 136x    \n",
            "video:0kB audio:2626kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.002901%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a1.mp3':\n",
            "  Duration: 00:00:58.44, start: 0.025057, bitrate: 130 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 130 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a1.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=    2516kB time=00:00:58.40 bitrate= 352.8kbits/s speed= 158x    \n",
            "video:0kB audio:2515kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.003028%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a9.mp3':\n",
            "  Duration: 00:00:28.08, start: 0.025057, bitrate: 131 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 131 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a9.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=    1208kB time=00:00:28.04 bitrate= 352.8kbits/s speed= 159x    \n",
            "video:0kB audio:1208kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.006307%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a4.mp3':\n",
            "  Duration: 00:00:38.16, start: 0.025057, bitrate: 130 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 130 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a4.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=    1642kB time=00:00:38.13 bitrate= 352.8kbits/s speed= 163x    \n",
            "video:0kB audio:1642kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.004638%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a8.mp3':\n",
            "  Duration: 00:00:27.35, start: 0.025057, bitrate: 132 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 132 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a8.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=    1177kB time=00:00:27.31 bitrate= 352.8kbits/s speed= 307x    \n",
            "video:0kB audio:1176kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.006475%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a7.mp3':\n",
            "  Duration: 00:00:17.79, start: 0.025057, bitrate: 132 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 132 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a7.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=     764kB time=00:00:17.74 bitrate= 352.8kbits/s speed= 338x    \n",
            "video:0kB audio:764kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.009966%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from './a6.mp3':\n",
            "  Duration: 00:00:11.70, start: 0.025057, bitrate: 131 kb/s\n",
            "    Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 131 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to 'out/./a6.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=     503kB time=00:00:11.67 bitrate= 352.9kbits/s speed= 212x    \n",
            "video:0kB audio:503kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.015148%\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a2.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:59.73, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a2.wav: No such file or directory\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a3.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:01:02.16, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a3.wav: No such file or directory\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a5.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:01:00.97, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a5.wav: No such file or directory\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a1.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:58.41, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a1.wav: No such file or directory\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a9.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:28.04, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a9.wav: No such file or directory\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a4.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:38.13, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a4.wav: No such file or directory\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a8.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:27.32, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a8.wav: No such file or directory\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a7.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:17.75, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a7.wav: No such file or directory\n",
            "\u001b[0mffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mInput #0, wav, from './out/a6.wav':\n",
            "  Metadata:\n",
            "    encoder         : Lavf58.29.100\n",
            "  Duration: 00:00:11.68, bitrate: 352 kb/s\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 22050 Hz, mono, s16, 352 kb/s\n",
            "\u001b[1;31mout/./out/a6.wav: No such file or directory\n",
            "\u001b[0mtotal 15687\n",
            "-rw------- 1 root root 2575916 Mar  5 15:34 a1.wav\n",
            "-rw------- 1 root root 2634238 Mar  5 15:34 a2.wav\n",
            "-rw------- 1 root root 2741160 Mar  5 15:34 a3.wav\n",
            "-rw------- 1 root root 1681664 Mar  5 15:34 a4.wav\n",
            "-rw------- 1 root root 2688736 Mar  5 15:34 a5.wav\n",
            "-rw------- 1 root root  514996 Mar  5 15:34 a6.wav\n",
            "-rw------- 1 root root  782732 Mar  5 15:34 a7.wav\n",
            "-rw------- 1 root root 1204752 Mar  5 15:34 a8.wav\n",
            "-rw------- 1 root root 1236828 Mar  5 15:34 a9.wav\n",
            "/content/drive/MyDrive/mp3uploads/out\n",
            "\n",
            "Input File     : 'a1.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:00:58.41 = 1287919 samples ~ 4380.68 CDDA sectors\n",
            "File Size      : 2.58M\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:00:58.41 [00:00:00.00] Out:1.29M [ -====|====- ]        Clip:0    \n",
            "Done.\n",
            "\n",
            "Input File     : 'a2.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:00:59.73 = 1317080 samples ~ 4479.86 CDDA sectors\n",
            "File Size      : 2.63M\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:00:59.73 [00:00:00.00] Out:1.31M [ =====|===== ]        Clip:0    \n",
            "Done.\n",
            "\n",
            "Input File     : 'a3.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:01:02.16 = 1370541 samples ~ 4661.7 CDDA sectors\n",
            "File Size      : 2.74M\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:01:02.16 [00:00:00.00] Out:1.37M [ -====|====- ]        Clip:0    \n",
            "Done.\n",
            "\n",
            "Input File     : 'a4.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:00:38.13 = 840793 samples ~ 2859.84 CDDA sectors\n",
            "File Size      : 1.68M\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:00:38.13 [00:00:00.00] Out:841k  [ -====|====- ]        Clip:0    \n",
            "Done.\n",
            "\n",
            "Input File     : 'a5.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:01:00.97 = 1344329 samples ~ 4572.55 CDDA sectors\n",
            "File Size      : 2.69M\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:01:00.97 [00:00:00.00] Out:1.33M [ =====|===== ]        Clip:0    \n",
            "Done.\n",
            "\n",
            "Input File     : 'a6.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:00:11.68 = 257459 samples ~ 875.711 CDDA sectors\n",
            "File Size      : 515k\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:00:11.68 [00:00:00.00] Out:257k  [ -====|====- ]        Clip:0    \n",
            "Done.\n",
            "\n",
            "Input File     : 'a7.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:00:17.75 = 391327 samples ~ 1331.04 CDDA sectors\n",
            "File Size      : 783k\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:00:17.75 [00:00:00.00] Out:362k  [ -====|====- ]        Clip:0    \n",
            "Done.\n",
            "\n",
            "Input File     : 'a8.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:00:27.32 = 602337 samples ~ 2048.77 CDDA sectors\n",
            "File Size      : 1.20M\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:00:27.32 [00:00:00.00] Out:602k  [ -====|====- ]        Clip:0    \n",
            "Done.\n",
            "\n",
            "Input File     : 'a9.wav'\n",
            "Channels       : 1\n",
            "Sample Rate    : 22050\n",
            "Precision      : 16-bit\n",
            "Duration       : 00:00:28.04 = 618375 samples ~ 2103.32 CDDA sectors\n",
            "File Size      : 1.24M\n",
            "Bit Rate       : 353k\n",
            "Sample Encoding: 16-bit Signed Integer PCM\n",
            "\n",
            "In:100%  00:00:28.04 [00:00:00.00] Out:618k  [ =====|===== ]        Clip:0    \n",
            "Done.\n",
            "/content/drive/MyDrive/mp3uploads/out/splits\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "%cd $upload_dir\n",
        "!rm -rf $upload_dir/out\n",
        "!mkdir $upload_dir/out\n",
        "!find . -name '*.mp3' -exec bash -c 'for f; do ffmpeg -i \"$f\" -acodec pcm_s16le -ar 22050 -ac 1 out/\"${f%.mp3}\".wav ; done' _ {} +\n",
        "!find . -name '*.wav' -exec bash -c 'for f; do ffmpeg -i \"$f\" -acodec pcm_s16le -ar 22050 -ac 1 out/\"${f%.wav}\".wav ; done' _ {} +\n",
        "\n",
        "\n",
        "!ls -al $upload_dir/out\n",
        "!mkdir $upload_dir/out/splits\n",
        "%cd $upload_dir/out\n",
        "!for FILE in *.wav; do sox \"$FILE\" splits/\"$FILE\" --show-progress silence 1 0.5 0.1% 1 0.5 0.1% : newfile : restart ; done\n",
        "#alt split method: force splits of 8 seconds, however this will split words. Comment the above with # and remove the # below to change\n",
        "#!for FILE in *.wav; do sox \"$FILE\" splits/\"$FILE\" --show-progress trim 0 8 : restart ; done\n",
        "%cd $upload_dir/out/splits\n",
        "!find . -name \"*.wav\" -type f -size -15k -delete"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIoB1kJFVbvm"
      },
      "source": [
        "(Optional) Run rnnoise, processed clips will be saved to your Google Drive in a folder named 'converted'. Files converted to 22khz mono for VITS model fine tuning.\n",
        "\n",
        "Original author unknown, but thank you for posting this helpful code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzfmkv0aWN-7",
        "outputId": "cea8d65a-7486-4970-a03b-1df55e80def4",
        "collapsed": true,
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a1001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a1001.wav\n",
            "\n",
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a2001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a2001.wav\n",
            "\n",
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a3001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a3001.wav\n",
            "\n",
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a4001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a4001.wav\n",
            "\n",
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a5001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a5001.wav\n",
            "\n",
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a6001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a6001.wav\n",
            "\n",
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a7001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a7001.wav\n",
            "\n",
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a8001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a8001.wav\n",
            "\n",
            "From: /content/drive/MyDrive/mp3uploads/out/splits/a9001.wav\n",
            "To: /content/drive/MyDrive/me2-dataset/converted/a9001.wav\n",
            "\n",
            "/content/drive/MyDrive/me2-dataset/converted\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "orig_wavs= upload_dir + \"/out/splits\"\n",
        "from pathlib import Path\n",
        "import os\n",
        "import subprocess\n",
        "import soundfile as sf\n",
        "import pyloudnorm as pyln\n",
        "import sys\n",
        "import glob\n",
        "rnn = \"/content/rnnoise/examples/rnnoise_demo\"\n",
        "paths = glob.glob(os.path.join(orig_wavs, '*.wav'))\n",
        "for filepath in paths:\n",
        "  base = os.path.basename(filepath)\n",
        "  tp_s = \"/content/drive/MyDrive/\" + dataset_name + \"/\" + \"converted\" + \"/\"\n",
        "  tf_s = \"/content/drive/MyDrive/\" + dataset_name + \"/\" + \"converted\" + \"/\" + base\n",
        "  target_path = Path(tp_s)\n",
        "  target_file = Path(tf_s)\n",
        "  print(\"From: \" + str(filepath))\n",
        "  print(\"To: \" + str(target_file))\n",
        "\t\n",
        "# Stereo to Mono; upsample to 48000Hz\n",
        "# added -G to fix gain, -v 0.95\n",
        "  subprocess.run([\"sox\", \"-G\", \"-v\", \"0.95\", filepath, \"48k.wav\", \"remix\", \"-\", \"rate\", \"48000\"])\n",
        "  subprocess.run([\"sox\", \"48k.wav\", \"-c\", \"1\", \"-r\", \"48000\", \"-b\", \"16\", \"-e\", \"signed-integer\", \"-t\", \"raw\", \"temp.raw\"]) # convert wav to raw\n",
        "  subprocess.run([\"/content/rnnoise/examples/rnnoise_demo\", \"temp.raw\", \"rnn.raw\"]) # apply rnnoise\n",
        "  subprocess.run([\"sox\", \"-G\", \"-v\", \"0.95\", \"-r\", \"48k\", \"-b\", \"16\", \"-e\", \"signed-integer\", \"rnn.raw\", \"-t\", \"wav\", \"rnn.wav\"]) # convert raw back to wav\n",
        "\n",
        "  subprocess.run([\"mkdir\", \"-p\", str(target_path)])\n",
        "  subprocess.run([\"sox\", \"rnn.wav\", str(target_file), \"remix\", \"-\", \"highpass\", \"100\", \"lowpass\", \"7000\", \"rate\", \"22050\"]) # apply high/low pass filter and change sr to 22050Hz\n",
        "  data, rate = sf.read(target_file)\n",
        "\n",
        "# peak normalize audio to -1 dB\n",
        "  peak_normalized_audio = pyln.normalize.peak(data, -1.0)\n",
        "\n",
        "# measure the loudness first\n",
        "  meter = pyln.Meter(rate) # create BS.1770 meter\n",
        "  loudness = meter.integrated_loudness(data)\n",
        "\n",
        "# loudness normalize audio to -25 dB LUFS\n",
        "  loudness_normalized_audio = pyln.normalize.loudness(data, loudness, -25.0)\n",
        "  sf.write(target_file, data=loudness_normalized_audio, samplerate=22050)\n",
        "  print(\"\")\n",
        "%cd /content/drive/MyDrive/\"$dataset_name\"/converted/\n",
        "!find . -name \"*.wav\" -type f -size -15k -delete\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy wav files to dataset wav directory"
      ],
      "metadata": {
        "id": "uS_4pqVCZ2hy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGAeXxPa1vnF",
        "outputId": "9f5b895c-d93a-44a0-e3fc-434fede1cc48",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/me2-dataset/wavs’: File exists\n",
            "total 15585\n",
            "-rw------- 1 root root 2573720 Mar  5 15:35 a1001.wav\n",
            "-rw------- 1 root root 2623994 Mar  5 15:35 a2001.wav\n",
            "-rw------- 1 root root 2740418 Mar  5 15:35 a3001.wav\n",
            "-rw------- 1 root root 1680254 Mar  5 15:35 a4001.wav\n",
            "-rw------- 1 root root 2661478 Mar  5 15:35 a5001.wav\n",
            "-rw------- 1 root root  514250 Mar  5 15:35 a6001.wav\n",
            "-rw------- 1 root root  722842 Mar  5 15:35 a7001.wav\n",
            "-rw------- 1 root root 1203974 Mar  5 15:35 a8001.wav\n",
            "-rw------- 1 root root 1236168 Mar  5 15:35 a9001.wav\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!mkdir /content/drive/MyDrive/$dataset_name/wavs\n",
        "!cp /content/drive/MyDrive/$dataset_name/converted/*.wav /content/drive/MyDrive/$dataset_name/wavs\n",
        "!ls -al /content/drive/MyDrive/$dataset_name/wavs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Whisper on generated audio clips, generate transcript named metadata.csv in LJSpeech format in the dataset directory."
      ],
      "metadata": {
        "id": "bUwJq6WOjNz5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SPp7FX6viuQe",
        "cellView": "form",
        "outputId": "abbb2b8c-73d5-4f0e-ad6c-97e6a70186dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "a1001|I have no sleep. No sleep! No sleep! Anyway. Bottom teeth revealed. No! No no no no no. I'm not gonna keep you that long for this stream. I don't think it's gonna be like the full hour long cuz I don't- I mean unless we get talking about something but otherwise I think this will be like a little bit extreme. What dances are you practicing? I can't tell you if I tell you not to kill you but I can't tell you. Oh but I can tell you that it's from quite a few. I need- ha! I need more time! I need more time! I only have like- what is it? Two days? Two days? Two days to learn? What is it? It was two days to learn. Uh... three? Three dances? Not enough time for me. I need more time. I need more time. Hopefully get more time.|I have no sleep. No sleep! No sleep! Anyway. Bottom teeth revealed. No! No no no no no. I'm not gonna keep you that long for this stream. I don't think it's gonna be like the full hour long cuz I don't- I mean unless we get talking about something but otherwise I think this will be like a little bit extreme. What dances are you practicing? I can't tell you if I tell you not to kill you but I can't tell you. Oh but I can tell you that it's from quite a few. I need- ha! I need more time! I need more time! I only have like- what is it? Two days? Two days? Two days to learn? What is it? It was two days to learn. Uh... three? Three dances? Not enough time for me. I need more time. I need more time. Hopefully get more time.\n",
            "\n",
            "a2001|Did you party too hard yesterday? Me? No. No, I was trapped in the recording studio all day. I was trapped in the recording studio all day. It was kind of like a party though, with all the snacks that the staff brought. I told members about this, but yeah. I was really busy. I was in the recording studio, pretty much all, but there was a lot of snacks. The snack table was immaculate. It was amazing. It was glorious. I wanted to take a picture, but I didn't want to be weird. I bumped into Iris. I bumped into Iris. I saw freaking Iris. I met Iris for the first time. First time meeting Iris. She's so, so cute. I was so exhausted though. I was so tired. I was like, I want to jump up and hug you Iris, but I saw it. I don't know. I feel bad. I have to tell her. I think she knew though because I think she records a lot, a lot, a lot.|Did you party too hard yesterday? Me? No. No, I was trapped in the recording studio all day. I was trapped in the recording studio all day. It was kind of like a party though, with all the snacks that the staff brought. I told members about this, but yeah. I was really busy. I was in the recording studio, pretty much all, but there was a lot of snacks. The snack table was immaculate. It was amazing. It was glorious. I wanted to take a picture, but I didn't want to be weird. I bumped into Iris. I bumped into Iris. I saw freaking Iris. I met Iris for the first time. First time meeting Iris. She's so, so cute. I was so exhausted though. I was so tired. I was like, I want to jump up and hug you Iris, but I saw it. I don't know. I feel bad. I have to tell her. I think she knew though because I think she records a lot, a lot, a lot.\n",
            "\n",
            "a3001|I don't know, but I want to hang out with Iris more. I want to like go get our nails done or something. Something really girly and fun. I think it'd be cute. Hi Iris, you make Iris! I did it! I did. Did you say hi Iris? I didn't! I was too brain dead! I was too brain dead. It was like five hours or so of singing and I was dead tired by the time I saw Iris. Oh no, temptations everywhere. So many! Oh my god. Okay, so the table of schnakes, right schnakes? And then they grab, there's like a little Famimart hololive thing. And staff snuck into Famimart and totally scored the hololive goods and was like, here Guru, do you want any of these? I was like, yes, thank you. Thank you very much. Did somebody say the IRS? No, well, I don't think Iris is the IRS.|I don't know, but I want to hang out with Iris more. I want to like go get our nails done or something. Something really girly and fun. I think it'd be cute. Hi Iris, you make Iris! I did it! I did. Did you say hi Iris? I didn't! I was too brain dead! I was too brain dead. It was like five hours or so of singing and I was dead tired by the time I saw Iris. Oh no, temptations everywhere. So many! Oh my god. Okay, so the table of schnakes, right schnakes? And then they grab, there's like a little Famimart hololive thing. And staff snuck into Famimart and totally scored the hololive goods and was like, here Guru, do you want any of these? I was like, yes, thank you. Thank you very much. Did somebody say the IRS? No, well, I don't think Iris is the IRS.\n",
            "\n",
            "a4001|she's too cute to be the IRS sorry I don't think is anybody that works at the IRS considered cute are there any cute people that work at the IRS that's how they get you they get you by being super cute I still see my microphone being kind of weird I don't know why why why why why okay I will trust you that it's okay I'm sorry I keep getting stuck on it I keep getting stuck on it stuck on it|she's too cute to be the IRS sorry I don't think is anybody that works at the IRS considered cute are there any cute people that work at the IRS that's how they get you they get you by being super cute I still see my microphone being kind of weird I don't know why why why why why okay I will trust you that it's okay I'm sorry I keep getting stuck on it I keep getting stuck on it stuck on it\n",
            "\n",
            "a5001|like a grocery bag? I don't know if you guys have paper grocery bags where you're from? It's like a gift bag. It has a ribbon handle. It's very thick. It was very pressed and clean, but I crumbled it a little bit. And they gave it to me like this, and I was like, okay, I will return this exactly as you gave it to me. Thank you very much. That's why I was like, you know... I don't know, maybe my parents trained me. Did you guys during Christmas or birthdays, do you ever reuse the really nice wrapping stuff? Like wrapping paper, that's really nice. Ribbons that are really nice and bags that are really nice. You always save them to reuse them. But no, I guess not. I guess the paper bag is whatever, but no, they're gonna... You know what? I told them. They told... and then I got pinged in the discord. They're like, it's okay, girl. Like, you can have the bag. It's like, it's fine. Don't worry about it. And I said, no! You are going to take this bag back.|like a grocery bag? I don't know if you guys have paper grocery bags where you're from? It's like a gift bag. It has a ribbon handle. It's very thick. It was very pressed and clean, but I crumbled it a little bit. And they gave it to me like this, and I was like, okay, I will return this exactly as you gave it to me. Thank you very much. That's why I was like, you know... I don't know, maybe my parents trained me. Did you guys during Christmas or birthdays, do you ever reuse the really nice wrapping stuff? Like wrapping paper, that's really nice. Ribbons that are really nice and bags that are really nice. You always save them to reuse them. But no, I guess not. I guess the paper bag is whatever, but no, they're gonna... You know what? I told them. They told... and then I got pinged in the discord. They're like, it's okay, girl. Like, you can have the bag. It's like, it's fine. Don't worry about it. And I said, no! You are going to take this bag back.\n",
            "\n",
            "a6001|Exactly how you gave it to me, in pristine condition. Take the damn bag.|Exactly how you gave it to me, in pristine condition. Take the damn bag.\n",
            "\n",
            "a7001|like a grocery bag I don't know if you guys have paper grocery bags where you're from it's like a gift bag it has a ribbon handle it's very thick it was very like pressed and clean but I crumbled it a little bit|like a grocery bag I don't know if you guys have paper grocery bags where you're from it's like a gift bag it has a ribbon handle it's very thick it was very like pressed and clean but I crumbled it a little bit\n",
            "\n",
            "a8001|And they gave it to me like this and I'm like okay, I will I Will return this exactly as you gave it to me. Thank you very much. That's like, you know, I Don't know maybe my parents trained me did you guys during Christmas or birthdays? Do you ever reuse the really nice wrapping stuff like wrapping paper? That's really nice Ribbons that are really nice and bags that are really nice. You always save them to reuse them|And they gave it to me like this and I'm like okay, I will I Will return this exactly as you gave it to me. Thank you very much. That's like, you know, I Don't know maybe my parents trained me did you guys during Christmas or birthdays? Do you ever reuse the really nice wrapping stuff like wrapping paper? That's really nice Ribbons that are really nice and bags that are really nice. You always save them to reuse them\n",
            "\n",
            "a9001|But no, I guess not. I guess the paper bag is whatever, but no, they're gonna- you know what? I told them, they told- and then I got- I got pinged in the discord. They were like, it's okay, girl, like, you can have the bag, it's like, it's fine, don't worry about it. And I said, no! You are going to take this bag back exactly how you gave it to me, in pristine condition. Take the damn bag.|But no, I guess not. I guess the paper bag is whatever, but no, they're gonna- you know what? I told them, they told- and then I got- I got pinged in the discord. They were like, it's okay, girl, like, you can have the bag, it's like, it's fine, don't worry about it. And I said, no! You are going to take this bag back exactly how you gave it to me, in pristine condition. Take the damn bag.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "import whisper\n",
        "import os, os.path\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "wavs = '/content/drive/MyDrive/'+dataset_name+'/wavs'\n",
        "\n",
        "model = whisper.load_model(\"medium.en\")\n",
        "paths = glob.glob(os.path.join(wavs, '*.wav'))\n",
        "print(len(paths))\n",
        "\n",
        "all_filenames = []\n",
        "transcript_text = []\n",
        "with open('/content/drive/MyDrive/'+dataset_name+'/metadata.csv', 'w', encoding='utf-8') as outfile:\n",
        "\tfor filepath in paths:\n",
        "\t\tbase = os.path.basename(filepath)\n",
        "\t\tall_filenames.append(base)\n",
        "\tfor filepath in paths:\n",
        "\t\tresult = model.transcribe(filepath)\n",
        "\t\toutput = result[\"text\"].lstrip()\n",
        "\t\toutput = output.replace(\"\\n\",\"\")\n",
        "\t\tthefile = str(os.path.basename(filepath).lstrip(\".\")).rsplit(\".\")[0]\n",
        "\t\toutfile.write(thefile + '|' + output + '|' + output + '\\n')\n",
        "\t\tprint(thefile + '|' + output + '|' + output + '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display dataset"
      ],
      "metadata": {
        "id": "pekKe4Ibeddj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIVhvXY4jb1m",
        "outputId": "4e5fcd42-a970-4c07-a703-d939231e9c87",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gura001|I have no sleep. No sleep! No sleep! Anyway. Bottom teeth revealed. No! No no no no no. I'm not gonna keep you that long for this stream. I don't think it's gonna be like the full hour long cuz I don't- I mean unless we get talking about something but otherwise I think this will be like a little bobby stream. What dances are you practicing? I can't tell you if I tell you not to kill you but I can't tell you. Oh but I can tell you that it's from quite a few. I need- ha! I need more time! I need more time! I only have like- what is it? Two days? Two days? Two days to learn? What is it? It was two days to learn. Uh three? Three dances? Not enough time for me. I need more time. I need more time. Hopefully get more time. Did you party too hard yesterday? Me? No! No I was trapped in a- I was trapped in the recording studio all day. I was trapped in the recording studio all day. It was kinda like a party though with all the snacks that the staff brought. I told members about this but yeah. I was really busy. I was in the recording studio. Pretty much all- but there was a lot of snacks. The snack table was immaculate. It was amazing. It was glorious. I wanted to take a picture but I didn't want to be weird. Yeah. I bumped into Iris! I bumped into Iris! I saw freaking Iris! I met Iris for the- I think it was the first time. First time meeting Iris. And she's so so cute. I was so exhausted though. I was so tired. I didn't- I was like- I wanna jump open and hug you Iris but I saw it. I don't know I feel bad. I have to tell her like I'm so sorry. I think she knew though. Cause she- I think she records a lot a lot a lot. So yeah. I don't know. But I wanna hang out with Iris more. I wanna like go get our nails done or something. Something really girly and fun. I think it'd be cute. Iris you met Iris! I did! I did. Did you say Iris? I didn't! I was too branded! I was too branded. It was like five hours- five hours or so? Of singing and I was dead tired by the time. Uh I saw Iris. Oh no! Temptations everywhere! It's so bad! Oh my god! Okay so the table of schnakes right? Schnakes. And then! And then they grabbed- there's like a- there's like a little uh fami- famimart hololive thing. And staff- staff snuck into famimart and totally scored the hololive goods and was like here girl do you want any of these? I was like yes! Thank you! Thank you very much! Did somebody say the IRS? No! Well I don't think Iris is the IRS. She's too cute to be the IRS. Sorry. I don't think- is anybody that works at the IRS considered cute? Are there any cute people that work at the IRS? No? That's how they get you! They get you by being super cute. I still see my microphone being kind of weird. I don't know why! Why? Why? Why? Why? Okay, I will trust you that it's okay. I'm sorry. I keep getting stuck on it. I keep getting stuck on it, stuck on it, stuck on it.|I have no sleep. No sleep! No sleep! Anyway. Bottom teeth revealed. No! No no no no no. I'm not gonna keep you that long for this stream. I don't think it's gonna be like the full hour long cuz I don't- I mean unless we get talking about something but otherwise I think this will be like a little bobby stream. What dances are you practicing? I can't tell you if I tell you not to kill you but I can't tell you. Oh but I can tell you that it's from quite a few. I need- ha! I need more time! I need more time! I only have like- what is it? Two days? Two days? Two days to learn? What is it? It was two days to learn. Uh three? Three dances? Not enough time for me. I need more time. I need more time. Hopefully get more time. Did you party too hard yesterday? Me? No! No I was trapped in a- I was trapped in the recording studio all day. I was trapped in the recording studio all day. It was kinda like a party though with all the snacks that the staff brought. I told members about this but yeah. I was really busy. I was in the recording studio. Pretty much all- but there was a lot of snacks. The snack table was immaculate. It was amazing. It was glorious. I wanted to take a picture but I didn't want to be weird. Yeah. I bumped into Iris! I bumped into Iris! I saw freaking Iris! I met Iris for the- I think it was the first time. First time meeting Iris. And she's so so cute. I was so exhausted though. I was so tired. I didn't- I was like- I wanna jump open and hug you Iris but I saw it. I don't know I feel bad. I have to tell her like I'm so sorry. I think she knew though. Cause she- I think she records a lot a lot a lot. So yeah. I don't know. But I wanna hang out with Iris more. I wanna like go get our nails done or something. Something really girly and fun. I think it'd be cute. Iris you met Iris! I did! I did. Did you say Iris? I didn't! I was too branded! I was too branded. It was like five hours- five hours or so? Of singing and I was dead tired by the time. Uh I saw Iris. Oh no! Temptations everywhere! It's so bad! Oh my god! Okay so the table of schnakes right? Schnakes. And then! And then they grabbed- there's like a- there's like a little uh fami- famimart hololive thing. And staff- staff snuck into famimart and totally scored the hololive goods and was like here girl do you want any of these? I was like yes! Thank you! Thank you very much! Did somebody say the IRS? No! Well I don't think Iris is the IRS. She's too cute to be the IRS. Sorry. I don't think- is anybody that works at the IRS considered cute? Are there any cute people that work at the IRS? No? That's how they get you! They get you by being super cute. I still see my microphone being kind of weird. I don't know why! Why? Why? Why? Why? Okay, I will trust you that it's okay. I'm sorry. I keep getting stuck on it. I keep getting stuck on it, stuck on it, stuck on it.\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "!cat /content/drive/MyDrive/$dataset_name/metadata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX5ftK4TzPUD"
      },
      "source": [
        "Download VITS model and Generate Sample Wav File to /content/ljspeech-vits.wav  This will be deleted when your Colab session is closed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vy-BadvazVNM",
        "outputId": "4b5ca34b-e1f6-4f13-82f1-6e17de188272",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > tts_models/en/ljspeech/vits is already downloaded.\n",
            " > Using model: vits\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Text: I am the very model of a modern Major General\n",
            " > Text splitted to sentences.\n",
            "['I am the very model of a modern Major General']\n",
            " > Processing time: 5.6706554889678955\n",
            " > Real-time factor: 1.5453573454091123\n",
            " > Saving output to /content/ljspeech-vits.wav\n"
          ]
        }
      ],
      "source": [
        "!tts --text \"I am the very model of a modern Major General\" --model_name \"tts_models/en/ljspeech/vits\" --out_path /content/ljspeech-vits.wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hkv4z1YcOfL"
      },
      "source": [
        "Save the training script with your dataset name, and output dir set. File will be saved in your Google drive dataset folder as train_vits.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vTTt1CacqmF8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69eea0d-e3f0-48dd-89a9-ad9b01261724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 3057 Mar  5 15:50 /content/drive/MyDrive/me2-dataset/train_vits.py\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "code = \"\"\"import os\n",
        "\n",
        "from trainer import Trainer, TrainerArgs\n",
        "\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "from TTS.tts.configs.vits_config import VitsConfig\n",
        "from TTS.tts.datasets import load_tts_samples\n",
        "from TTS.tts.models.vits import Vits, VitsAudioConfig\n",
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "from TTS.utils.audio import AudioProcessor\n",
        "\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
        "\n",
        "#output_path = os.path.dirname(os.path.abspath(__file__))\n",
        "##########################################\n",
        "#Change this to your dataset directory\n",
        "##########################################\n",
        "output_path = \"/content/drive/MyDrive/\"\"\"\n",
        "code = code + dataset_name + \"/\" + output_directory + \"/\" + \"\\\"\"\n",
        "\n",
        "code=code + \"\"\"\n",
        "dataset_config = BaseDatasetConfig(\n",
        "##########################################\n",
        "#Change this to your dataset directory\n",
        "##########################################\n",
        "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"/content/drive/MyDrive/\"\"\"\n",
        "code = code + dataset_name\n",
        "code=code + \"\"\"\")\n",
        "\n",
        ")\n",
        "audio_config = VitsAudioConfig(\n",
        "    sample_rate=22050, win_length=1024, hop_length=256, num_mels=80, mel_fmin=0, mel_fmax=None\n",
        ")\n",
        "\n",
        "config = VitsConfig(\n",
        "    audio=audio_config,\n",
        "    run_name=\"vits_ljspeech\",\n",
        "    batch_size=4,\n",
        "    eval_batch_size=4,\n",
        "    batch_group_size=2,\n",
        "#    num_loader_workers=8,\n",
        "    num_loader_workers=1,\n",
        "    num_eval_loader_workers=1,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=1000,\n",
        "    save_step=1000,\n",
        "\t  save_checkpoints=True,\n",
        "\t  save_n_checkpoints=4,\n",
        "\t  save_best_after=1000,\n",
        "    #text_cleaner=\"english_cleaners\",\n",
        "    text_cleaner=\"multilingual_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    compute_input_seq_cache=True,\n",
        "    print_step=25,\n",
        "    print_eval=True,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    cudnn_benchmark=False,\n",
        "\n",
        ")\n",
        "\n",
        "# INITIALIZE THE AUDIO PROCESSOR\n",
        "# Audio processor is used for feature extraction and audio I/O.\n",
        "# It mainly serves to the dataloader and the training loggers.\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "\n",
        "# INITIALIZE THE TOKENIZER\n",
        "# Tokenizer is used to convert text to sequences of token IDs.\n",
        "# config is updated with the default characters if not defined in the config.\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
        "\n",
        "# LOAD DATA SAMPLES\n",
        "# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
        "# You can define your custom sample loader returning the list of samples.\n",
        "# Or define your custom formatter and pass it to the `load_tts_samples`.\n",
        "# Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=0.1111111111111111,\n",
        ")\n",
        "\n",
        "# init model\n",
        "model = Vits(config, ap, tokenizer, speaker_manager=None)\n",
        "\n",
        "# init the trainer and begin\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(),\n",
        "    config,\n",
        "    output_path,\n",
        "    model=model,\n",
        "    train_samples=train_samples,\n",
        "    eval_samples=eval_samples,\n",
        "  \n",
        ")\n",
        "trainer.fit()\n",
        "\"\"\"\n",
        "#print(code)\n",
        "myFile = open(\"/content/drive/MyDrive/\" + dataset_name + \"/train_vits.py\", 'w')\n",
        "\n",
        "myFile.write(code)\n",
        "myFile.close()\n",
        "%ls -al /content/drive/MyDrive/$dataset_name/train_vits.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS08OyEVzeJA"
      },
      "source": [
        "Fine Tune VITS model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "VXIGWKv1Wd4Q",
        "outputId": "76e4963a-21aa-4f55-c1fc-ab28be34fc39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DviNKw7rzkyK",
        "outputId": "7c9f46d3-3fc0-4924-91c3-f45c43a6c0ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " | > Found 9 files in /content/drive/MyDrive/me2-dataset\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            " > Training Environment:\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " > Start Tensorboard: tensorboard --logdir=/content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            " > Restoring from model_file.pth ...\n",
            " > Restoring Model...\n",
            " > Partial model initialization...\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.0.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.0.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.0.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.1.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.1.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.1.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.2.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.2.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.2.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.3.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.3.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.3.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.4.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.4.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.4.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.5.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.5.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.0.convs.5.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.0.conv_post.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.0.conv_post.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.0.conv_post.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.0.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.0.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.0.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.1.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.1.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.1.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.2.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.2.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.2.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.3.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.3.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.3.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.4.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.4.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.1.convs.4.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.1.conv_post.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.1.conv_post.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.1.conv_post.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.0.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.0.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.0.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.1.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.1.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.1.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.2.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.2.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.2.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.3.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.3.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.3.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.4.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.4.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.2.convs.4.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.2.conv_post.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.2.conv_post.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.2.conv_post.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.0.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.0.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.0.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.1.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.1.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.1.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.2.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.2.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.2.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.3.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.3.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.3.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.4.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.4.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.3.convs.4.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.3.conv_post.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.3.conv_post.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.3.conv_post.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.0.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.0.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.0.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.1.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.1.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.1.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.2.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.2.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.2.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.3.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.3.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.3.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.4.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.4.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.4.convs.4.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.4.conv_post.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.4.conv_post.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.4.conv_post.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.0.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.0.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.0.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.1.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.1.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.1.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.2.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.2.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.2.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.3.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.3.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.3.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.4.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.4.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.5.convs.4.weight_v\n",
            " | > Layer missing in the checkpoint: disc.nets.5.conv_post.bias\n",
            " | > Layer missing in the checkpoint: disc.nets.5.conv_post.weight_g\n",
            " | > Layer missing in the checkpoint: disc.nets.5.conv_post.weight_v\n",
            " | > Layer dimention missmatch between model definition and checkpoint: text_encoder.emb.weight\n",
            " | > 837 / 949 layers are restored.\n",
            " > Model restored from step 1000000\n",
            "\n",
            " > Model has 83059180 parameters\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:38:12) \u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 6.04426  (6.04426)\n",
            "     | > loss_disc_real_0: 1.04670  (1.04670)\n",
            "     | > loss_disc_real_1: 1.03582  (1.03582)\n",
            "     | > loss_disc_real_2: 0.97203  (0.97203)\n",
            "     | > loss_disc_real_3: 0.98163  (0.98163)\n",
            "     | > loss_disc_real_4: 0.97740  (0.97740)\n",
            "     | > loss_disc_real_5: 1.02920  (1.02920)\n",
            "     | > loss_0: 6.04426  (6.04426)\n",
            "     | > loss_gen: 6.04318  (6.04318)\n",
            "     | > loss_kl: 14.16851  (14.16851)\n",
            "     | > loss_feat: 0.30218  (0.30218)\n",
            "     | > loss_mel: 22.66599  (22.66599)\n",
            "     | > loss_duration: 0.31839  (0.31839)\n",
            "     | > loss_1: 43.49826  (43.49826)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "/usr/local/lib/python3.8/dist-packages/TTS/tts/models/vits.py:1452: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
            "  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 1.35752 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc: 6.04426 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_0: 1.04670 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_1: 1.03582 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_2: 0.97203 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_3: 0.98163 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_4: 0.97740 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_5: 1.02920 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_0: 6.04426 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_gen: 6.04318 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_kl: 14.16851 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_feat: 0.30218 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_mel: 22.66599 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_duration: 0.31839 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_1: 43.49826 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000/best_model_1000003.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:38:41) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.40516  (3.40516)\n",
            "     | > loss_disc_real_0: 0.39286  (0.39286)\n",
            "     | > loss_disc_real_1: 0.45428  (0.45428)\n",
            "     | > loss_disc_real_2: 0.38921  (0.38921)\n",
            "     | > loss_disc_real_3: 0.44820  (0.44820)\n",
            "     | > loss_disc_real_4: 0.43915  (0.43915)\n",
            "     | > loss_disc_real_5: 0.58101  (0.58101)\n",
            "     | > loss_0: 3.40516  (3.40516)\n",
            "     | > loss_gen: 2.70201  (2.70201)\n",
            "     | > loss_kl: 14.26180  (14.26180)\n",
            "     | > loss_feat: 0.24175  (0.24175)\n",
            "     | > loss_mel: 30.98810  (30.98810)\n",
            "     | > loss_duration: 0.24261  (0.24261)\n",
            "     | > loss_1: 48.43628  (48.43628)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.14107 \u001b[0m(-1.21645)\n",
            "     | > avg_loss_disc:\u001b[92m 3.40516 \u001b[0m(-2.63910)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.39286 \u001b[0m(-0.65384)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.45428 \u001b[0m(-0.58154)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.38921 \u001b[0m(-0.58281)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.44820 \u001b[0m(-0.53343)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.43915 \u001b[0m(-0.53825)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.58101 \u001b[0m(-0.44820)\n",
            "     | > avg_loss_0:\u001b[92m 3.40516 \u001b[0m(-2.63910)\n",
            "     | > avg_loss_gen:\u001b[92m 2.70201 \u001b[0m(-3.34118)\n",
            "     | > avg_loss_kl:\u001b[91m 14.26180 \u001b[0m(+0.09330)\n",
            "     | > avg_loss_feat:\u001b[92m 0.24175 \u001b[0m(-0.06043)\n",
            "     | > avg_loss_mel:\u001b[91m 30.98810 \u001b[0m(+8.32211)\n",
            "     | > avg_loss_duration:\u001b[92m 0.24261 \u001b[0m(-0.07578)\n",
            "     | > avg_loss_1:\u001b[91m 48.43628 \u001b[0m(+4.93802)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:39:01) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.45442  (3.45442)\n",
            "     | > loss_disc_real_0: 0.11804  (0.11804)\n",
            "     | > loss_disc_real_1: 0.12996  (0.12996)\n",
            "     | > loss_disc_real_2: 0.16038  (0.16038)\n",
            "     | > loss_disc_real_3: 0.15399  (0.15399)\n",
            "     | > loss_disc_real_4: 0.17203  (0.17203)\n",
            "     | > loss_disc_real_5: 0.12105  (0.12105)\n",
            "     | > loss_0: 3.45442  (3.45442)\n",
            "     | > loss_gen: 0.85544  (0.85544)\n",
            "     | > loss_kl: 14.80027  (14.80027)\n",
            "     | > loss_feat: 0.00055  (0.00055)\n",
            "     | > loss_mel: 11.91832  (11.91832)\n",
            "     | > loss_duration: 0.27338  (0.27338)\n",
            "     | > loss_1: 27.84795  (27.84795)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.12986 \u001b[0m(-0.01121)\n",
            "     | > avg_loss_disc:\u001b[91m 3.45442 \u001b[0m(+0.04927)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.11804 \u001b[0m(-0.27482)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.12996 \u001b[0m(-0.32432)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.16038 \u001b[0m(-0.22883)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.15399 \u001b[0m(-0.29421)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.17203 \u001b[0m(-0.26712)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.12105 \u001b[0m(-0.45996)\n",
            "     | > avg_loss_0:\u001b[91m 3.45442 \u001b[0m(+0.04927)\n",
            "     | > avg_loss_gen:\u001b[92m 0.85544 \u001b[0m(-1.84657)\n",
            "     | > avg_loss_kl:\u001b[91m 14.80027 \u001b[0m(+0.53847)\n",
            "     | > avg_loss_feat:\u001b[92m 0.00055 \u001b[0m(-0.24121)\n",
            "     | > avg_loss_mel:\u001b[92m 11.91832 \u001b[0m(-19.06978)\n",
            "     | > avg_loss_duration:\u001b[91m 0.27338 \u001b[0m(+0.03076)\n",
            "     | > avg_loss_1:\u001b[92m 27.84795 \u001b[0m(-20.58833)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000/best_model_1000007.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:39:25) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.23380  (3.23380)\n",
            "     | > loss_disc_real_0: 0.16278  (0.16278)\n",
            "     | > loss_disc_real_1: 0.37937  (0.37937)\n",
            "     | > loss_disc_real_2: 0.41489  (0.41489)\n",
            "     | > loss_disc_real_3: 0.38406  (0.38406)\n",
            "     | > loss_disc_real_4: 0.40513  (0.40513)\n",
            "     | > loss_disc_real_5: 0.36189  (0.36189)\n",
            "     | > loss_0: 3.23380  (3.23380)\n",
            "     | > loss_gen: 2.10937  (2.10937)\n",
            "     | > loss_kl: 19.31500  (19.31500)\n",
            "     | > loss_feat: 0.10458  (0.10458)\n",
            "     | > loss_mel: 33.94105  (33.94105)\n",
            "     | > loss_duration: 0.30498  (0.30498)\n",
            "     | > loss_1: 55.77499  (55.77499)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.15182 \u001b[0m(+0.02196)\n",
            "     | > avg_loss_disc:\u001b[92m 3.23380 \u001b[0m(-0.22062)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.16278 \u001b[0m(+0.04474)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.37937 \u001b[0m(+0.24941)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.41489 \u001b[0m(+0.25451)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.38406 \u001b[0m(+0.23007)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.40513 \u001b[0m(+0.23310)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.36189 \u001b[0m(+0.24084)\n",
            "     | > avg_loss_0:\u001b[92m 3.23380 \u001b[0m(-0.22062)\n",
            "     | > avg_loss_gen:\u001b[91m 2.10937 \u001b[0m(+1.25394)\n",
            "     | > avg_loss_kl:\u001b[91m 19.31500 \u001b[0m(+4.51473)\n",
            "     | > avg_loss_feat:\u001b[91m 0.10458 \u001b[0m(+0.10403)\n",
            "     | > avg_loss_mel:\u001b[91m 33.94105 \u001b[0m(+22.02273)\n",
            "     | > avg_loss_duration:\u001b[91m 0.30498 \u001b[0m(+0.03161)\n",
            "     | > avg_loss_1:\u001b[91m 55.77499 \u001b[0m(+27.92704)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:39:46) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.18198  (3.18198)\n",
            "     | > loss_disc_real_0: 0.28789  (0.28789)\n",
            "     | > loss_disc_real_1: 0.34799  (0.34799)\n",
            "     | > loss_disc_real_2: 0.36398  (0.36398)\n",
            "     | > loss_disc_real_3: 0.35856  (0.35856)\n",
            "     | > loss_disc_real_4: 0.36669  (0.36669)\n",
            "     | > loss_disc_real_5: 0.44656  (0.44656)\n",
            "     | > loss_0: 3.18198  (3.18198)\n",
            "     | > loss_gen: 2.17555  (2.17555)\n",
            "     | > loss_kl: 15.79243  (15.79243)\n",
            "     | > loss_feat: 0.28008  (0.28008)\n",
            "     | > loss_mel: 24.95185  (24.95185)\n",
            "     | > loss_duration: 0.54709  (0.54709)\n",
            "     | > loss_1: 43.74700  (43.74700)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.12516 \u001b[0m(-0.02666)\n",
            "     | > avg_loss_disc:\u001b[92m 3.18198 \u001b[0m(-0.05182)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.28789 \u001b[0m(+0.12512)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.34799 \u001b[0m(-0.03138)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.36398 \u001b[0m(-0.05091)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.35856 \u001b[0m(-0.02550)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.36669 \u001b[0m(-0.03844)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.44656 \u001b[0m(+0.08466)\n",
            "     | > avg_loss_0:\u001b[92m 3.18198 \u001b[0m(-0.05182)\n",
            "     | > avg_loss_gen:\u001b[91m 2.17555 \u001b[0m(+0.06618)\n",
            "     | > avg_loss_kl:\u001b[92m 15.79243 \u001b[0m(-3.52258)\n",
            "     | > avg_loss_feat:\u001b[91m 0.28008 \u001b[0m(+0.17550)\n",
            "     | > avg_loss_mel:\u001b[92m 24.95185 \u001b[0m(-8.98921)\n",
            "     | > avg_loss_duration:\u001b[91m 0.54709 \u001b[0m(+0.24211)\n",
            "     | > avg_loss_1:\u001b[92m 43.74700 \u001b[0m(-12.02798)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:40:05) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.11868  (3.11868)\n",
            "     | > loss_disc_real_0: 0.35387  (0.35387)\n",
            "     | > loss_disc_real_1: 0.20784  (0.20784)\n",
            "     | > loss_disc_real_2: 0.21650  (0.21650)\n",
            "     | > loss_disc_real_3: 0.22683  (0.22683)\n",
            "     | > loss_disc_real_4: 0.22911  (0.22911)\n",
            "     | > loss_disc_real_5: 0.31473  (0.31473)\n",
            "     | > loss_0: 3.11868  (3.11868)\n",
            "     | > loss_gen: 1.55280  (1.55280)\n",
            "     | > loss_kl: 8.02278  (8.02278)\n",
            "     | > loss_feat: 0.26065  (0.26065)\n",
            "     | > loss_mel: 24.49018  (24.49018)\n",
            "     | > loss_duration: 1.02662  (1.02662)\n",
            "     | > loss_1: 35.35303  (35.35303)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.10053 \u001b[0m(-0.02463)\n",
            "     | > avg_loss_disc:\u001b[92m 3.11868 \u001b[0m(-0.06330)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.35387 \u001b[0m(+0.06598)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.20784 \u001b[0m(-0.14015)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.21650 \u001b[0m(-0.14749)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.22683 \u001b[0m(-0.13173)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.22911 \u001b[0m(-0.13758)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.31473 \u001b[0m(-0.13183)\n",
            "     | > avg_loss_0:\u001b[92m 3.11868 \u001b[0m(-0.06330)\n",
            "     | > avg_loss_gen:\u001b[92m 1.55280 \u001b[0m(-0.62275)\n",
            "     | > avg_loss_kl:\u001b[92m 8.02278 \u001b[0m(-7.76965)\n",
            "     | > avg_loss_feat:\u001b[92m 0.26065 \u001b[0m(-0.01943)\n",
            "     | > avg_loss_mel:\u001b[92m 24.49018 \u001b[0m(-0.46166)\n",
            "     | > avg_loss_duration:\u001b[91m 1.02662 \u001b[0m(+0.47953)\n",
            "     | > avg_loss_1:\u001b[92m 35.35303 \u001b[0m(-8.39397)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 6/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:40:24) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.11709  (3.11709)\n",
            "     | > loss_disc_real_0: 0.33046  (0.33046)\n",
            "     | > loss_disc_real_1: 0.22331  (0.22331)\n",
            "     | > loss_disc_real_2: 0.21116  (0.21116)\n",
            "     | > loss_disc_real_3: 0.23293  (0.23293)\n",
            "     | > loss_disc_real_4: 0.23844  (0.23844)\n",
            "     | > loss_disc_real_5: 0.21044  (0.21044)\n",
            "     | > loss_0: 3.11709  (3.11709)\n",
            "     | > loss_gen: 1.44860  (1.44860)\n",
            "     | > loss_kl: 6.48649  (6.48649)\n",
            "     | > loss_feat: 0.31074  (0.31074)\n",
            "     | > loss_mel: 24.95921  (24.95921)\n",
            "     | > loss_duration: 1.02949  (1.02949)\n",
            "     | > loss_1: 34.23453  (34.23453)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.10321 \u001b[0m(+0.00268)\n",
            "     | > avg_loss_disc:\u001b[92m 3.11709 \u001b[0m(-0.00158)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.33046 \u001b[0m(-0.02341)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.22331 \u001b[0m(+0.01547)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.21116 \u001b[0m(-0.00534)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.23293 \u001b[0m(+0.00610)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.23844 \u001b[0m(+0.00933)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.21044 \u001b[0m(-0.10429)\n",
            "     | > avg_loss_0:\u001b[92m 3.11709 \u001b[0m(-0.00158)\n",
            "     | > avg_loss_gen:\u001b[92m 1.44860 \u001b[0m(-0.10420)\n",
            "     | > avg_loss_kl:\u001b[92m 6.48649 \u001b[0m(-1.53629)\n",
            "     | > avg_loss_feat:\u001b[91m 0.31074 \u001b[0m(+0.05009)\n",
            "     | > avg_loss_mel:\u001b[91m 24.95921 \u001b[0m(+0.46902)\n",
            "     | > avg_loss_duration:\u001b[91m 1.02949 \u001b[0m(+0.00286)\n",
            "     | > avg_loss_1:\u001b[92m 34.23453 \u001b[0m(-1.11851)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 7/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:40:42) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.08675  (3.08675)\n",
            "     | > loss_disc_real_0: 0.26757  (0.26757)\n",
            "     | > loss_disc_real_1: 0.30654  (0.30654)\n",
            "     | > loss_disc_real_2: 0.30030  (0.30030)\n",
            "     | > loss_disc_real_3: 0.31121  (0.31121)\n",
            "     | > loss_disc_real_4: 0.31799  (0.31799)\n",
            "     | > loss_disc_real_5: 0.27351  (0.27351)\n",
            "     | > loss_0: 3.08675  (3.08675)\n",
            "     | > loss_gen: 1.77712  (1.77712)\n",
            "     | > loss_kl: 6.14817  (6.14817)\n",
            "     | > loss_feat: 0.00055  (0.00055)\n",
            "     | > loss_mel: 12.24678  (12.24678)\n",
            "     | > loss_duration: 1.08243  (1.08243)\n",
            "     | > loss_1: 21.25505  (21.25505)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.11080 \u001b[0m(+0.00759)\n",
            "     | > avg_loss_disc:\u001b[92m 3.08675 \u001b[0m(-0.03034)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.26757 \u001b[0m(-0.06289)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.30654 \u001b[0m(+0.08323)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.30030 \u001b[0m(+0.08914)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.31121 \u001b[0m(+0.07827)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.31799 \u001b[0m(+0.07956)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.27351 \u001b[0m(+0.06307)\n",
            "     | > avg_loss_0:\u001b[92m 3.08675 \u001b[0m(-0.03034)\n",
            "     | > avg_loss_gen:\u001b[91m 1.77712 \u001b[0m(+0.32851)\n",
            "     | > avg_loss_kl:\u001b[92m 6.14817 \u001b[0m(-0.33832)\n",
            "     | > avg_loss_feat:\u001b[92m 0.00055 \u001b[0m(-0.31020)\n",
            "     | > avg_loss_mel:\u001b[92m 12.24678 \u001b[0m(-12.71242)\n",
            "     | > avg_loss_duration:\u001b[91m 1.08243 \u001b[0m(+0.05295)\n",
            "     | > avg_loss_1:\u001b[92m 21.25505 \u001b[0m(-12.97948)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000/best_model_1000017.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 8/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:41:11) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.08086  (3.08086)\n",
            "     | > loss_disc_real_0: 0.22543  (0.22543)\n",
            "     | > loss_disc_real_1: 0.28614  (0.28614)\n",
            "     | > loss_disc_real_2: 0.30512  (0.30512)\n",
            "     | > loss_disc_real_3: 0.29637  (0.29637)\n",
            "     | > loss_disc_real_4: 0.30205  (0.30205)\n",
            "     | > loss_disc_real_5: 0.33252  (0.33252)\n",
            "     | > loss_0: 3.08086  (3.08086)\n",
            "     | > loss_gen: 1.75085  (1.75085)\n",
            "     | > loss_kl: 5.62795  (5.62795)\n",
            "     | > loss_feat: 0.17808  (0.17808)\n",
            "     | > loss_mel: 36.42624  (36.42624)\n",
            "     | > loss_duration: 1.00416  (1.00416)\n",
            "     | > loss_1: 44.98728  (44.98728)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.36124 \u001b[0m(+0.25044)\n",
            "     | > avg_loss_disc:\u001b[92m 3.08086 \u001b[0m(-0.00589)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.22543 \u001b[0m(-0.04214)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.28614 \u001b[0m(-0.02040)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.30512 \u001b[0m(+0.00482)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.29637 \u001b[0m(-0.01484)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.30205 \u001b[0m(-0.01594)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.33252 \u001b[0m(+0.05900)\n",
            "     | > avg_loss_0:\u001b[92m 3.08086 \u001b[0m(-0.00589)\n",
            "     | > avg_loss_gen:\u001b[92m 1.75085 \u001b[0m(-0.02627)\n",
            "     | > avg_loss_kl:\u001b[92m 5.62795 \u001b[0m(-0.52022)\n",
            "     | > avg_loss_feat:\u001b[91m 0.17808 \u001b[0m(+0.17753)\n",
            "     | > avg_loss_mel:\u001b[91m 36.42624 \u001b[0m(+24.17946)\n",
            "     | > avg_loss_duration:\u001b[92m 1.00416 \u001b[0m(-0.07827)\n",
            "     | > avg_loss_1:\u001b[91m 44.98728 \u001b[0m(+23.73223)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 9/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:41:36) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.07094  (3.07094)\n",
            "     | > loss_disc_real_0: 0.23027  (0.23027)\n",
            "     | > loss_disc_real_1: 0.23063  (0.23063)\n",
            "     | > loss_disc_real_2: 0.24430  (0.24430)\n",
            "     | > loss_disc_real_3: 0.24088  (0.24088)\n",
            "     | > loss_disc_real_4: 0.24493  (0.24493)\n",
            "     | > loss_disc_real_5: 0.28851  (0.28851)\n",
            "     | > loss_0: 3.07094  (3.07094)\n",
            "     | > loss_gen: 1.47952  (1.47952)\n",
            "     | > loss_kl: 4.94308  (4.94308)\n",
            "     | > loss_feat: 0.00036  (0.00036)\n",
            "     | > loss_mel: 9.04418  (9.04418)\n",
            "     | > loss_duration: 1.06303  (1.06303)\n",
            "     | > loss_1: 16.53017  (16.53017)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.11250 \u001b[0m(-0.24874)\n",
            "     | > avg_loss_disc:\u001b[92m 3.07094 \u001b[0m(-0.00992)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.23027 \u001b[0m(+0.00485)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.23063 \u001b[0m(-0.05551)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.24430 \u001b[0m(-0.06081)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.24088 \u001b[0m(-0.05549)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.24493 \u001b[0m(-0.05712)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.28851 \u001b[0m(-0.04400)\n",
            "     | > avg_loss_0:\u001b[92m 3.07094 \u001b[0m(-0.00992)\n",
            "     | > avg_loss_gen:\u001b[92m 1.47952 \u001b[0m(-0.27133)\n",
            "     | > avg_loss_kl:\u001b[92m 4.94308 \u001b[0m(-0.68487)\n",
            "     | > avg_loss_feat:\u001b[92m 0.00036 \u001b[0m(-0.17772)\n",
            "     | > avg_loss_mel:\u001b[92m 9.04418 \u001b[0m(-27.38207)\n",
            "     | > avg_loss_duration:\u001b[91m 1.06303 \u001b[0m(+0.05887)\n",
            "     | > avg_loss_1:\u001b[92m 16.53017 \u001b[0m(-28.45712)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000/best_model_1000021.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 10/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:42:07) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.05934  (3.05934)\n",
            "     | > loss_disc_real_0: 0.26197  (0.26197)\n",
            "     | > loss_disc_real_1: 0.25306  (0.25306)\n",
            "     | > loss_disc_real_2: 0.23993  (0.23993)\n",
            "     | > loss_disc_real_3: 0.26716  (0.26716)\n",
            "     | > loss_disc_real_4: 0.26502  (0.26502)\n",
            "     | > loss_disc_real_5: 0.23621  (0.23621)\n",
            "     | > loss_0: 3.05934  (3.05934)\n",
            "     | > loss_gen: 1.52317  (1.52317)\n",
            "     | > loss_kl: 4.33541  (4.33541)\n",
            "     | > loss_feat: 0.37231  (0.37231)\n",
            "     | > loss_mel: 19.27253  (19.27253)\n",
            "     | > loss_duration: 1.03272  (1.03272)\n",
            "     | > loss_1: 26.53613  (26.53613)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.24796 \u001b[0m(+0.13546)\n",
            "     | > avg_loss_disc:\u001b[92m 3.05934 \u001b[0m(-0.01160)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.26197 \u001b[0m(+0.03169)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.25306 \u001b[0m(+0.02243)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.23993 \u001b[0m(-0.00437)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26716 \u001b[0m(+0.02629)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.26502 \u001b[0m(+0.02009)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.23621 \u001b[0m(-0.05230)\n",
            "     | > avg_loss_0:\u001b[92m 3.05934 \u001b[0m(-0.01160)\n",
            "     | > avg_loss_gen:\u001b[91m 1.52317 \u001b[0m(+0.04364)\n",
            "     | > avg_loss_kl:\u001b[92m 4.33541 \u001b[0m(-0.60768)\n",
            "     | > avg_loss_feat:\u001b[91m 0.37231 \u001b[0m(+0.37196)\n",
            "     | > avg_loss_mel:\u001b[91m 19.27253 \u001b[0m(+10.22835)\n",
            "     | > avg_loss_duration:\u001b[92m 1.03272 \u001b[0m(-0.03031)\n",
            "     | > avg_loss_1:\u001b[91m 26.53613 \u001b[0m(+10.00596)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 11/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:42:33) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.04731  (3.04731)\n",
            "     | > loss_disc_real_0: 0.28327  (0.28327)\n",
            "     | > loss_disc_real_1: 0.28240  (0.28240)\n",
            "     | > loss_disc_real_2: 0.27920  (0.27920)\n",
            "     | > loss_disc_real_3: 0.28565  (0.28565)\n",
            "     | > loss_disc_real_4: 0.28807  (0.28807)\n",
            "     | > loss_disc_real_5: 0.27065  (0.27065)\n",
            "     | > loss_0: 3.04731  (3.04731)\n",
            "     | > loss_gen: 1.69533  (1.69533)\n",
            "     | > loss_kl: 4.24133  (4.24133)\n",
            "     | > loss_feat: 0.30218  (0.30218)\n",
            "     | > loss_mel: 23.44757  (23.44757)\n",
            "     | > loss_duration: 0.95196  (0.95196)\n",
            "     | > loss_1: 30.63837  (30.63837)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.15436 \u001b[0m(-0.09360)\n",
            "     | > avg_loss_disc:\u001b[92m 3.04731 \u001b[0m(-0.01203)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.28327 \u001b[0m(+0.02130)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.28240 \u001b[0m(+0.02934)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.27920 \u001b[0m(+0.03927)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.28565 \u001b[0m(+0.01849)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.28807 \u001b[0m(+0.02305)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.27065 \u001b[0m(+0.03443)\n",
            "     | > avg_loss_0:\u001b[92m 3.04731 \u001b[0m(-0.01203)\n",
            "     | > avg_loss_gen:\u001b[91m 1.69533 \u001b[0m(+0.17216)\n",
            "     | > avg_loss_kl:\u001b[92m 4.24133 \u001b[0m(-0.09407)\n",
            "     | > avg_loss_feat:\u001b[92m 0.30218 \u001b[0m(-0.07013)\n",
            "     | > avg_loss_mel:\u001b[91m 23.44757 \u001b[0m(+4.17505)\n",
            "     | > avg_loss_duration:\u001b[92m 0.95196 \u001b[0m(-0.08076)\n",
            "     | > avg_loss_1:\u001b[91m 30.63837 \u001b[0m(+4.10225)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 12/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:42:53) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0/2 -- GLOBAL_STEP: 1000025\u001b[0m\n",
            "     | > loss_disc: 3.05180  (3.05180)\n",
            "     | > loss_disc_real_0: 0.28314  (0.28314)\n",
            "     | > loss_disc_real_1: 0.28177  (0.28177)\n",
            "     | > loss_disc_real_2: 0.27842  (0.27842)\n",
            "     | > loss_disc_real_3: 0.28467  (0.28467)\n",
            "     | > loss_disc_real_4: 0.28761  (0.28761)\n",
            "     | > loss_disc_real_5: 0.27007  (0.27007)\n",
            "     | > loss_0: 3.05180  (3.05180)\n",
            "     | > grad_norm_0: 0.60863  (0.60863)\n",
            "     | > loss_gen: 1.66736  (1.66736)\n",
            "     | > loss_kl: 3.82289  (3.82289)\n",
            "     | > loss_feat: 0.32643  (0.32643)\n",
            "     | > loss_mel: 20.43412  (20.43412)\n",
            "     | > loss_duration: 1.53366  (1.53366)\n",
            "     | > amp_scaler: 256.00000  (256.00000)\n",
            "     | > loss_1: 27.78444  (27.78444)\n",
            "     | > grad_norm_1: 322.82687  (322.82687)\n",
            "     | > current_lr_0: 0.00020 \n",
            "     | > current_lr_1: 0.00020 \n",
            "     | > step_time: 5.35460  (5.35457)\n",
            "     | > loader_time: 0.29260  (0.29259)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.04400  (3.04400)\n",
            "     | > loss_disc_real_0: 0.27583  (0.27583)\n",
            "     | > loss_disc_real_1: 0.25490  (0.25490)\n",
            "     | > loss_disc_real_2: 0.27077  (0.27077)\n",
            "     | > loss_disc_real_3: 0.25312  (0.25312)\n",
            "     | > loss_disc_real_4: 0.25612  (0.25612)\n",
            "     | > loss_disc_real_5: 0.28041  (0.28041)\n",
            "     | > loss_0: 3.04400  (3.04400)\n",
            "     | > loss_gen: 1.59177  (1.59177)\n",
            "     | > loss_kl: 4.06843  (4.06843)\n",
            "     | > loss_feat: 0.23676  (0.23676)\n",
            "     | > loss_mel: 20.43095  (20.43095)\n",
            "     | > loss_duration: 1.11888  (1.11888)\n",
            "     | > loss_1: 27.44679  (27.44679)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.15598 \u001b[0m(+0.00163)\n",
            "     | > avg_loss_disc:\u001b[92m 3.04400 \u001b[0m(-0.00331)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.27583 \u001b[0m(-0.00744)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.25490 \u001b[0m(-0.02750)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.27077 \u001b[0m(-0.00843)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.25312 \u001b[0m(-0.03253)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.25612 \u001b[0m(-0.03195)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.28041 \u001b[0m(+0.00977)\n",
            "     | > avg_loss_0:\u001b[92m 3.04400 \u001b[0m(-0.00331)\n",
            "     | > avg_loss_gen:\u001b[92m 1.59177 \u001b[0m(-0.10356)\n",
            "     | > avg_loss_kl:\u001b[92m 4.06843 \u001b[0m(-0.17291)\n",
            "     | > avg_loss_feat:\u001b[92m 0.23676 \u001b[0m(-0.06542)\n",
            "     | > avg_loss_mel:\u001b[92m 20.43095 \u001b[0m(-3.01662)\n",
            "     | > avg_loss_duration:\u001b[91m 1.11888 \u001b[0m(+0.16692)\n",
            "     | > avg_loss_1:\u001b[92m 27.44679 \u001b[0m(-3.19159)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 13/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:43:11) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.03794  (3.03794)\n",
            "     | > loss_disc_real_0: 0.25490  (0.25490)\n",
            "     | > loss_disc_real_1: 0.24990  (0.24990)\n",
            "     | > loss_disc_real_2: 0.24650  (0.24650)\n",
            "     | > loss_disc_real_3: 0.26350  (0.26350)\n",
            "     | > loss_disc_real_4: 0.26193  (0.26193)\n",
            "     | > loss_disc_real_5: 0.24475  (0.24475)\n",
            "     | > loss_0: 3.03794  (3.03794)\n",
            "     | > loss_gen: 1.52146  (1.52146)\n",
            "     | > loss_kl: 4.19390  (4.19390)\n",
            "     | > loss_feat: 0.00065  (0.00065)\n",
            "     | > loss_mel: 10.79375  (10.79375)\n",
            "     | > loss_duration: 1.07694  (1.07694)\n",
            "     | > loss_1: 17.58670  (17.58670)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.09878 \u001b[0m(-0.05720)\n",
            "     | > avg_loss_disc:\u001b[92m 3.03794 \u001b[0m(-0.00606)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.25490 \u001b[0m(-0.02093)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.24990 \u001b[0m(-0.00501)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.24650 \u001b[0m(-0.02427)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.26350 \u001b[0m(+0.01038)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.26193 \u001b[0m(+0.00581)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24475 \u001b[0m(-0.03566)\n",
            "     | > avg_loss_0:\u001b[92m 3.03794 \u001b[0m(-0.00606)\n",
            "     | > avg_loss_gen:\u001b[92m 1.52146 \u001b[0m(-0.07031)\n",
            "     | > avg_loss_kl:\u001b[91m 4.19390 \u001b[0m(+0.12547)\n",
            "     | > avg_loss_feat:\u001b[92m 0.00065 \u001b[0m(-0.23611)\n",
            "     | > avg_loss_mel:\u001b[92m 10.79375 \u001b[0m(-9.63721)\n",
            "     | > avg_loss_duration:\u001b[92m 1.07694 \u001b[0m(-0.04194)\n",
            "     | > avg_loss_1:\u001b[92m 17.58670 \u001b[0m(-9.86009)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 14/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:43:29) \u001b[0m\n",
            " ! Run is kept in /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+38PM-0000000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/trainer/trainer.py\", line 1591, in fit\n",
            "    self._fit()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/trainer/trainer.py\", line 1544, in _fit\n",
            "    self.train_epoch()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/trainer/trainer.py\", line 1309, in train_epoch\n",
            "    _, _ = self.train_step(batch, batch_num_steps, cur_step, loader_start_time)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/trainer/trainer.py\", line 1162, in train_step\n",
            "    outputs, loss_dict_new, step_time = self._optimize(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/trainer/trainer.py\", line 1023, in _optimize\n",
            "    outputs, loss_dict = self._model_train_step(batch, model, criterion, optimizer_idx=optimizer_idx)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/trainer/trainer.py\", line 970, in _model_train_step\n",
            "    return model.train_step(*input_args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/TTS/tts/models/vits.py\", line 1265, in train_step\n",
            "    scores_disc_fake, _, scores_disc_real, _ = self.disc(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/TTS/tts/layers/vits/discriminator.py\", line 82, in forward\n",
            "    x_score, x_feat = net(x)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/TTS/vocoder/models/hifigan_discriminator.py\", line 68, in forward\n",
            "    x = l(x)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1212, in _call_impl\n",
            "    result = forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\", line 463, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py\", line 459, in _conv_forward\n",
            "    return F.conv2d(input, weight, bias, self.stride,\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.75 GiB total capacity; 9.17 GiB already allocated; 832.00 KiB free; 9.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=\"0\" python /content/drive/MyDrive/$dataset_name/train_vits.py --restore_path /root/.local/share/tts/tts_models--en--ljspeech--vits/model_file.pth --config_file /root/.local/share/tts/tts_models--en--ljspeech--vits/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3ydXqTyj-IH"
      },
      "source": [
        "**Resume a fine tuning session**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQYhcr_we74L"
      },
      "source": [
        "Run the next cell to list all of the saved run direcories.  Copy select the run you want to resume, ctrl+C to copy the name. Paste in the next cell and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vzxhbrTV8aw",
        "outputId": "8c2f702c-8d6a-4282-caed-654aa41e00d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "phoneme_cache  vits_ljspeech-March-05-2023_03+38PM-0000000\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/$dataset_name/$output_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "g0mC-appmrRk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "run_name = \"vits_ljspeech-March-05-2023_03+38PM-0000000\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2YVQGVrfM67"
      },
      "source": [
        "Run this cell to list all of the checkpoints in the saved run, then put the checkpoint name in the next cell, and run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa2YtWfHZ4Xj",
        "outputId": "47c8398a-7b73-4375-d969-5b9d3b9f1387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_1000021.pth\tevents.out.tfevents.1678030690.3fa06e6e8b22\n",
            "best_model.pth\t\ttrainer_0_log.txt\n",
            "config.json\t\ttrain_vits.py\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/$dataset_name/$output_directory/$run_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1Z59OjTpZ4ha",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"best_model_1000021.pth\" #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2WQUoLhfrUu"
      },
      "source": [
        "Run the next cell to restore a previous fine tuning session using your dataset name, trainer output directory, and model checkpoint set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiM4XGXgnnIc",
        "outputId": "b18c98dd-f805-4bb8-9286-2a3ee3b9dfc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:0\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:None\n",
            " | > fft_size:1024\n",
            " | > power:None\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:None\n",
            " | > signal_norm:None\n",
            " | > symmetric_norm:None\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:None\n",
            " | > pitch_fmax:None\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:1.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:False\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " | > Found 9 files in /content/drive/MyDrive/me2-dataset\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            " > Training Environment:\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " > Start Tensorboard: tensorboard --logdir=/content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000\n",
            " > Restoring from best_model_1000021.pth ...\n",
            " > Restoring Model...\n",
            " > Restoring Optimizer...\n",
            " > Restoring Scaler...\n",
            " > Model restored from step 1000021\n",
            "\n",
            " > Model has 83059180 parameters\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:50:47) \u001b[0m\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:632: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:801.)\n",
            "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n",
            "/usr/local/lib/python3.8/dist-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.06917  (3.06917)\n",
            "     | > loss_disc_real_0: 0.24514  (0.24514)\n",
            "     | > loss_disc_real_1: 0.23295  (0.23295)\n",
            "     | > loss_disc_real_2: 0.22980  (0.22980)\n",
            "     | > loss_disc_real_3: 0.24580  (0.24580)\n",
            "     | > loss_disc_real_4: 0.24659  (0.24659)\n",
            "     | > loss_disc_real_5: 0.25482  (0.25482)\n",
            "     | > loss_0: 3.06917  (3.06917)\n",
            "     | > loss_gen: 1.45295  (1.45295)\n",
            "     | > loss_kl: 4.41772  (4.41772)\n",
            "     | > loss_feat: 0.29316  (0.29316)\n",
            "     | > loss_mel: 20.57007  (20.57007)\n",
            "     | > loss_duration: 1.05324  (1.05324)\n",
            "     | > loss_1: 27.78715  (27.78715)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "/usr/local/lib/python3.8/dist-packages/TTS/tts/models/vits.py:1452: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n",
            "  test_figures[\"{}-alignment\".format(idx)] = plot_alignment(alignment.T, output_fig=False)\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time: 0.17402 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc: 3.06917 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_0: 0.24514 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_1: 0.23295 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_2: 0.22980 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_3: 0.24580 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_4: 0.24659 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_disc_real_5: 0.25482 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_0: 3.06917 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_gen: 1.45295 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_kl: 4.41772 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_feat: 0.29316 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_mel: 20.57007 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_duration: 1.05324 \u001b[0m(+0.00000)\n",
            "     | > avg_loss_1: 27.78715 \u001b[0m(+0.00000)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000/best_model_1000024.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 1/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:51:30) \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 1/2 -- GLOBAL_STEP: 1000025\u001b[0m\n",
            "     | > loss_disc: 3.05860  (3.05860)\n",
            "     | > loss_disc_real_0: 0.26187  (0.26187)\n",
            "     | > loss_disc_real_1: 0.25405  (0.25405)\n",
            "     | > loss_disc_real_2: 0.24131  (0.24131)\n",
            "     | > loss_disc_real_3: 0.26830  (0.26830)\n",
            "     | > loss_disc_real_4: 0.26641  (0.26641)\n",
            "     | > loss_disc_real_5: 0.23694  (0.23694)\n",
            "     | > loss_0: 3.05860  (3.05860)\n",
            "     | > grad_norm_0: 0.64146  (0.64146)\n",
            "     | > loss_gen: 1.63632  (1.63632)\n",
            "     | > loss_kl: 4.47510  (4.47510)\n",
            "     | > loss_feat: 0.23742  (0.23742)\n",
            "     | > loss_mel: 23.94708  (23.94708)\n",
            "     | > loss_duration: 1.37630  (1.37630)\n",
            "     | > amp_scaler: 4096.00000  (4096.00000)\n",
            "     | > loss_1: 31.67222  (31.67222)\n",
            "     | > grad_norm_1: 0.00000  (0.00000)\n",
            "     | > current_lr_0: 0.00020 \n",
            "     | > current_lr_1: 0.00020 \n",
            "     | > step_time: 10.38230  (10.38234)\n",
            "     | > loader_time: 0.02200  (0.02204)\n",
            "\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.05470  (3.05470)\n",
            "     | > loss_disc_real_0: 0.27598  (0.27598)\n",
            "     | > loss_disc_real_1: 0.27558  (0.27558)\n",
            "     | > loss_disc_real_2: 0.26363  (0.26363)\n",
            "     | > loss_disc_real_3: 0.28682  (0.28682)\n",
            "     | > loss_disc_real_4: 0.28534  (0.28534)\n",
            "     | > loss_disc_real_5: 0.24938  (0.24938)\n",
            "     | > loss_0: 3.05470  (3.05470)\n",
            "     | > loss_gen: 1.63745  (1.63745)\n",
            "     | > loss_kl: 4.61616  (4.61616)\n",
            "     | > loss_feat: 0.29446  (0.29446)\n",
            "     | > loss_mel: 25.47931  (25.47931)\n",
            "     | > loss_duration: 1.09883  (1.09883)\n",
            "     | > loss_1: 33.12622  (33.12622)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.25668 \u001b[0m(+0.08266)\n",
            "     | > avg_loss_disc:\u001b[92m 3.05470 \u001b[0m(-0.01447)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.27598 \u001b[0m(+0.03084)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.27558 \u001b[0m(+0.04263)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26363 \u001b[0m(+0.03383)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.28682 \u001b[0m(+0.04102)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.28534 \u001b[0m(+0.03875)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24938 \u001b[0m(-0.00545)\n",
            "     | > avg_loss_0:\u001b[92m 3.05470 \u001b[0m(-0.01447)\n",
            "     | > avg_loss_gen:\u001b[91m 1.63745 \u001b[0m(+0.18450)\n",
            "     | > avg_loss_kl:\u001b[91m 4.61616 \u001b[0m(+0.19844)\n",
            "     | > avg_loss_feat:\u001b[91m 0.29446 \u001b[0m(+0.00130)\n",
            "     | > avg_loss_mel:\u001b[91m 25.47931 \u001b[0m(+4.90924)\n",
            "     | > avg_loss_duration:\u001b[91m 1.09883 \u001b[0m(+0.04559)\n",
            "     | > avg_loss_1:\u001b[91m 33.12622 \u001b[0m(+5.33907)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 2/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:51:56) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.04940  (3.04940)\n",
            "     | > loss_disc_real_0: 0.28297  (0.28297)\n",
            "     | > loss_disc_real_1: 0.27427  (0.27427)\n",
            "     | > loss_disc_real_2: 0.28370  (0.28370)\n",
            "     | > loss_disc_real_3: 0.27136  (0.27136)\n",
            "     | > loss_disc_real_4: 0.27710  (0.27710)\n",
            "     | > loss_disc_real_5: 0.28574  (0.28574)\n",
            "     | > loss_0: 3.04940  (3.04940)\n",
            "     | > loss_gen: 1.67514  (1.67514)\n",
            "     | > loss_kl: 5.15432  (5.15432)\n",
            "     | > loss_feat: 0.00050  (0.00050)\n",
            "     | > loss_mel: 18.55944  (18.55944)\n",
            "     | > loss_duration: 1.05729  (1.05729)\n",
            "     | > loss_1: 26.44668  (26.44668)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.16055 \u001b[0m(-0.09614)\n",
            "     | > avg_loss_disc:\u001b[92m 3.04940 \u001b[0m(-0.00531)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.28297 \u001b[0m(+0.00699)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.27427 \u001b[0m(-0.00131)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.28370 \u001b[0m(+0.02008)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.27136 \u001b[0m(-0.01546)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.27710 \u001b[0m(-0.00824)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.28574 \u001b[0m(+0.03637)\n",
            "     | > avg_loss_0:\u001b[92m 3.04940 \u001b[0m(-0.00531)\n",
            "     | > avg_loss_gen:\u001b[91m 1.67514 \u001b[0m(+0.03769)\n",
            "     | > avg_loss_kl:\u001b[91m 5.15432 \u001b[0m(+0.53816)\n",
            "     | > avg_loss_feat:\u001b[92m 0.00050 \u001b[0m(-0.29396)\n",
            "     | > avg_loss_mel:\u001b[92m 18.55944 \u001b[0m(-6.91987)\n",
            "     | > avg_loss_duration:\u001b[92m 1.05729 \u001b[0m(-0.04154)\n",
            "     | > avg_loss_1:\u001b[92m 26.44668 \u001b[0m(-6.67953)\n",
            "\n",
            " > BEST MODEL : /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000/best_model_1000028.pth\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 3/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:52:25) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.03597  (3.03597)\n",
            "     | > loss_disc_real_0: 0.26524  (0.26524)\n",
            "     | > loss_disc_real_1: 0.24372  (0.24372)\n",
            "     | > loss_disc_real_2: 0.25661  (0.25661)\n",
            "     | > loss_disc_real_3: 0.24919  (0.24919)\n",
            "     | > loss_disc_real_4: 0.25066  (0.25066)\n",
            "     | > loss_disc_real_5: 0.26196  (0.26196)\n",
            "     | > loss_0: 3.03597  (3.03597)\n",
            "     | > loss_gen: 1.53253  (1.53253)\n",
            "     | > loss_kl: 4.91709  (4.91709)\n",
            "     | > loss_feat: 0.11159  (0.11159)\n",
            "     | > loss_mel: 30.64653  (30.64653)\n",
            "     | > loss_duration: 1.06901  (1.06901)\n",
            "     | > loss_1: 38.27674  (38.27674)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[91m 0.22259 \u001b[0m(+0.06204)\n",
            "     | > avg_loss_disc:\u001b[92m 3.03597 \u001b[0m(-0.01343)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.26524 \u001b[0m(-0.01773)\n",
            "     | > avg_loss_disc_real_1:\u001b[92m 0.24372 \u001b[0m(-0.03055)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.25661 \u001b[0m(-0.02709)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.24919 \u001b[0m(-0.02218)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.25066 \u001b[0m(-0.02644)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.26196 \u001b[0m(-0.02378)\n",
            "     | > avg_loss_0:\u001b[92m 3.03597 \u001b[0m(-0.01343)\n",
            "     | > avg_loss_gen:\u001b[92m 1.53253 \u001b[0m(-0.14261)\n",
            "     | > avg_loss_kl:\u001b[92m 4.91709 \u001b[0m(-0.23722)\n",
            "     | > avg_loss_feat:\u001b[91m 0.11159 \u001b[0m(+0.11109)\n",
            "     | > avg_loss_mel:\u001b[91m 30.64653 \u001b[0m(+12.08709)\n",
            "     | > avg_loss_duration:\u001b[91m 1.06901 \u001b[0m(+0.01172)\n",
            "     | > avg_loss_1:\u001b[91m 38.27674 \u001b[0m(+11.83006)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 4/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:52:50) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.03380  (3.03380)\n",
            "     | > loss_disc_real_0: 0.24775  (0.24775)\n",
            "     | > loss_disc_real_1: 0.26004  (0.26004)\n",
            "     | > loss_disc_real_2: 0.24935  (0.24935)\n",
            "     | > loss_disc_real_3: 0.27251  (0.27251)\n",
            "     | > loss_disc_real_4: 0.27199  (0.27199)\n",
            "     | > loss_disc_real_5: 0.24125  (0.24125)\n",
            "     | > loss_0: 3.03380  (3.03380)\n",
            "     | > loss_gen: 1.54470  (1.54470)\n",
            "     | > loss_kl: 4.61770  (4.61770)\n",
            "     | > loss_feat: 0.29923  (0.29923)\n",
            "     | > loss_mel: 19.50739  (19.50739)\n",
            "     | > loss_duration: 1.16718  (1.16718)\n",
            "     | > loss_1: 27.13620  (27.13620)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.16548 \u001b[0m(-0.05711)\n",
            "     | > avg_loss_disc:\u001b[92m 3.03380 \u001b[0m(-0.00217)\n",
            "     | > avg_loss_disc_real_0:\u001b[92m 0.24775 \u001b[0m(-0.01749)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.26004 \u001b[0m(+0.01632)\n",
            "     | > avg_loss_disc_real_2:\u001b[92m 0.24935 \u001b[0m(-0.00726)\n",
            "     | > avg_loss_disc_real_3:\u001b[91m 0.27251 \u001b[0m(+0.02332)\n",
            "     | > avg_loss_disc_real_4:\u001b[91m 0.27199 \u001b[0m(+0.02133)\n",
            "     | > avg_loss_disc_real_5:\u001b[92m 0.24125 \u001b[0m(-0.02071)\n",
            "     | > avg_loss_0:\u001b[92m 3.03380 \u001b[0m(-0.00217)\n",
            "     | > avg_loss_gen:\u001b[91m 1.54470 \u001b[0m(+0.01217)\n",
            "     | > avg_loss_kl:\u001b[92m 4.61770 \u001b[0m(-0.29939)\n",
            "     | > avg_loss_feat:\u001b[91m 0.29923 \u001b[0m(+0.18764)\n",
            "     | > avg_loss_mel:\u001b[92m 19.50739 \u001b[0m(-11.13914)\n",
            "     | > avg_loss_duration:\u001b[91m 1.16718 \u001b[0m(+0.09817)\n",
            "     | > avg_loss_1:\u001b[92m 27.13620 \u001b[0m(-11.14055)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 5/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:53:10) \u001b[0m\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 1\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 421\n",
            " | > Min text length: 421\n",
            " | > Avg text length: 421.0\n",
            " | \n",
            " | > Max audio length: 601987.0\n",
            " | > Min audio length: 601987.0\n",
            " | > Avg audio length: 601987.0\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n",
            "\n",
            "\u001b[1m > EVALUATION \u001b[0m\n",
            "\n",
            "\u001b[1m   --> STEP: 0\u001b[0m\n",
            "     | > loss_disc: 3.02646  (3.02646)\n",
            "     | > loss_disc_real_0: 0.24926  (0.24926)\n",
            "     | > loss_disc_real_1: 0.26720  (0.26720)\n",
            "     | > loss_disc_real_2: 0.26773  (0.26773)\n",
            "     | > loss_disc_real_3: 0.25207  (0.25207)\n",
            "     | > loss_disc_real_4: 0.25509  (0.25509)\n",
            "     | > loss_disc_real_5: 0.26232  (0.26232)\n",
            "     | > loss_0: 3.02646  (3.02646)\n",
            "     | > loss_gen: 1.55695  (1.55695)\n",
            "     | > loss_kl: 4.84245  (4.84245)\n",
            "     | > loss_feat: 0.32738  (0.32738)\n",
            "     | > loss_mel: 22.02654  (22.02654)\n",
            "     | > loss_duration: 0.94800  (0.94800)\n",
            "     | > loss_1: 29.70131  (29.70131)\n",
            "\n",
            " | > Synthesizing test sentences.\n",
            "\n",
            "  \u001b[1m--> EVAL PERFORMANCE\u001b[0m\n",
            "     | > avg_loader_time:\u001b[92m 0.15810 \u001b[0m(-0.00738)\n",
            "     | > avg_loss_disc:\u001b[92m 3.02646 \u001b[0m(-0.00735)\n",
            "     | > avg_loss_disc_real_0:\u001b[91m 0.24926 \u001b[0m(+0.00151)\n",
            "     | > avg_loss_disc_real_1:\u001b[91m 0.26720 \u001b[0m(+0.00715)\n",
            "     | > avg_loss_disc_real_2:\u001b[91m 0.26773 \u001b[0m(+0.01838)\n",
            "     | > avg_loss_disc_real_3:\u001b[92m 0.25207 \u001b[0m(-0.02044)\n",
            "     | > avg_loss_disc_real_4:\u001b[92m 0.25509 \u001b[0m(-0.01689)\n",
            "     | > avg_loss_disc_real_5:\u001b[91m 0.26232 \u001b[0m(+0.02107)\n",
            "     | > avg_loss_0:\u001b[92m 3.02646 \u001b[0m(-0.00735)\n",
            "     | > avg_loss_gen:\u001b[91m 1.55695 \u001b[0m(+0.01225)\n",
            "     | > avg_loss_kl:\u001b[91m 4.84245 \u001b[0m(+0.22475)\n",
            "     | > avg_loss_feat:\u001b[91m 0.32738 \u001b[0m(+0.02815)\n",
            "     | > avg_loss_mel:\u001b[91m 22.02654 \u001b[0m(+2.51915)\n",
            "     | > avg_loss_duration:\u001b[92m 0.94800 \u001b[0m(-0.21917)\n",
            "     | > avg_loss_1:\u001b[91m 29.70131 \u001b[0m(+2.56511)\n",
            "\n",
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 6/1000\u001b[0m\n",
            " --> /content/drive/MyDrive/me2-dataset/traineroutput/vits_ljspeech-March-05-2023_03+50PM-0000000\n",
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: True\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "| > Number of instances : 8\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 965\n",
            " | > Min text length: 73\n",
            " | > Avg text length: 545.5\n",
            " | \n",
            " | > Max audio length: 1370209.0\n",
            " | > Min audio length: 257125.0\n",
            " | > Avg audio length: 922070.25\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 8.\n",
            "\n",
            "\u001b[1m > TRAINING (2023-03-05 15:53:29) \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!CUDA_VISIBLE_DEVICES=\"0\" python /content/drive/MyDrive/$dataset_name/train_vits.py --restore_path /content/drive/MyDrive/$dataset_name/$output_directory/$run_name/$model_checkpoint --config_path /content/drive/MyDrive/$dataset_name/$run_name/config.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZ2WoSCqzqxH"
      },
      "source": [
        "View Memory Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryma4sViztPk",
        "outputId": "43e68b75-7cea-4f48-db90-6b38eb12c4bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  5 15:49:18 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P0    30W /  70W |   4227MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ORJUVXnz4B5"
      },
      "source": [
        "Load Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gMqzKCacnPvX"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkt32dP3z9sK"
      },
      "source": [
        "Load Dashboard. May take several minutes to appear from a blank white box.  Ad blockers probably need to whitelist a bunch of Colab stuff or this won't wrok."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PxPBHCGf0AVt",
        "outputId": "b04ee1fa-43db-47fb-f5eb-d98d7b01b4c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        (async () => {\n",
              "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
              "            url.searchParams.set('tensorboardColab', 'true');\n",
              "            const iframe = document.createElement('iframe');\n",
              "            iframe.src = url;\n",
              "            iframe.setAttribute('width', '100%');\n",
              "            iframe.setAttribute('height', '800');\n",
              "            iframe.setAttribute('frameborder', 0);\n",
              "            document.body.appendChild(iframe);\n",
              "        })();\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/$dataset_name/$output_directory/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}